{"text":{"0":"My first question is WHY???\nBecause even the guy who invented that stupidity has said, that regularly password changes has been the most shitty idea he ever had.","1":"```PostgreSQL: OK\n superuser or standard user with backup privileges: OK\n PostgreSQL streaming: OK\n wal_level: OK\n replication slot: OK\n directories: OK\n retention policy settings: OK\n backup maximum age: OK (no last_backup_maximum_age provided)\n backup minimum size: OK (0 B)\n wal maximum age: OK (no last_wal_maximum_age provided)\n wal size: OK (0 B)\n compression settings: OK\n failed backups: OK (there are 0 failed backups)\n minimum redundancy requirements: OK (have 0 backups, expected at least 0)\n pg_basebackup: OK\n pg_basebackup compatible: OK\n pg_basebackup supports tablespaces mapping: OK\n systemid coherence: OK\n pg_receivexlog: FAILED\n pg_receivexlog compatible: FAILED (PostgreSQL version: 14.1, pg_receivexlog version: None)\n receive-wal running: OK\n archiver errors: FAILED (unknown: 1)```","2":"Just you??","3":"How to give access to a database to my friend in postgresql","4":"Can u pls eloborate it","5":"I guess no. And we're waiting for the client's input which will unlikely arrive since it's a few days old.\n\nif this a busy server with OLTP workload, having such long transaction already means that you have a lot of bloat -- long-running transactions block do not allow autovacuum to remove tuples recently became dead, database-wide","6":"+1, but unfortunately it will not happen... it's a long history...","7":"Help: I have installed pg 10 on RHEl, now how can I upgrade to pg 12","8":"Take a look at the documentation https:\/\/www.postgresql.org\/docs\/current\/logfile-maintenance.html\nThat should give you a starting point.","9":"Yes, you are missing the configuration in the pg_hba.conf file.\nhttps:\/\/www.postgresql.org\/docs\/current\/auth-pg-hba-conf.html","10":"fuzzy text search?","11":"Does the offer still stand?","12":"Sysmap is the configuration of network map, part of ui of zabbix server. I would check zabbix bugs mail lists if there are some bug related to this error. Second if you are in a test env you could try removing data that have risen fk error.","13":"Ah, indeed, didn't pay attention it's **derived** value.","14":"Any hints on how to improve CTEperformance","15":"Yes, by default \nhttps:\/\/sqlize.online\/sql\/psql14\/d891506cac9e9455f0a8207b91d7847c\/","16":"","17":"Why did you decide to build another tool for the job?","18":"","19":"Okay it worked","20":"Awesome.  Thanks","21":"Hi everyone!\nIs it possible to capture real-time data from the 'pg_stat_acivity' system view without using a tool like 'cron', and then record this data externally or in a table?","22":"that's the risk with json. In one object it can contain a string, and in the other it can contain a boolean, or a number. Very dynamic, but you have to be careful with it.","23":"Mind you, EDB offers a proprietary product. So you'll potentially just change the vendor you lock in with.\n\nDid you check https:\/\/www.postgresql.org\/support\/professional_support\/africa\/ ?","24":"version PG 14.2","25":"https:\/\/stackoverflow.com\/questions\/70363101\/installation-of-pg-cron-on-azure-flexible-postgesql","26":"Postgres Professional's fork","27":"If I column x has a not null constraint, why does the row estimate for the condition `x is not null` is 1 and not 0?","28":"Please rewrite your post, for assistance, and include the pertinent error messages...\n\nAlso, in order to this link to work, I assume that some PG library was installed on the Oracle machine...\nWas that version upgraded?\n\nBut your OP implied you were not connecting (it was failing).  As opposed to RETURNING an error after connecting...\nAlso, you could indicate if ALL queries fail, or only some?","29":"anyone knows how to connect pgadmin in localhost","30":"I mean -- I agree that pg_dump is not for backups, and many agree. But the documentation is still claiming the opposite. Any attempts to fix it?","31":"Regarding the kernel... It looks like your kernel misses POSIX compatiblity layer, you can try googling for that, it might be possible just to load missing module, or just enable it via modprobe.","32":"Also from the explain plan I see a bitmap heap scan being the expensive node","33":"Anyone who has set up an alert system for their application in postgres database.\u00a0 I need guidance on how to set up tables on our postgres that can handle incoming alerts from our application . Any documentation or any assistance is appreciated.\u00a0 Thanks","34":"Hi guys quick question.  I want to use COPY to read files from different location and I know I need pg_read_server_files role. However when I grant it to my admin user postgres am getting error that cannot grant without being a member of the role. Any assistance is appreciated","35":"First of all, this app supports line breaks!\n\nDo you have decent knowledge of:\n- PostgreSQL?\n- Oracle?\nIf you answer one of that questions with no, hire someone permanently or contract a consultant.\nBecause otherwise, the result will not be a success.\n\nThere are currently two tools available, doing this stuff. In addition one can use a foreign data wrapper.\nEvery decision has to be made on the type of usage and of code in Oracle. The size of a database doesn't relate to this.","36":"Does anyone use elephantsql? Does it help a lot of the optimization or it is good only for full stack guys who have no time for DB calibration?","37":"yes that i follow","38":"I will see here. Thanks very much.","39":"Sizes of the DBs -- it's only about the data and indexes","40":"So you use `jq` with `-c` option to minify your json and print one per line (as COPY expects)","41":"With MS SQL it's quite the contrary, obviously. ;)","42":"Ok Janine... thanks!!","43":"Yes you right","44":"also we have pgbouncers  in front of the postgres server..","45":"I failed to find those details ;)","46":"But that goes the same for Postgres, I guess.,","47":"PostgreSQL Person of the Week interview with: Stefanie Janine St\u00f6lting\n\nhttps:\/\/postgresql.life\/post\/stefanie_janine_stoelting\/","48":"Hello","49":"Not at all \u2014 if you're a usual DBA, you could usually impersonate a guru in both, no problem. ;)","50":"The ask here is to insert as many records as possible in 1 hour.\nRollback would not serve purpose","51":"SELECT pg_terminate_backend(pg_stat_activity.procpid) \n FROM pg_stat_get_activity(NULL::integer) \n WHERE datid=(SELECT oid from pg_database where datname = 'your_database');\nTo close all connections of posygres ?","52":"No","53":"[Fa Ch](tg:\/\/user?id=1165566068)","54":"Yes","55":"There are scenarios where the optimizer can eliminate complete branches when a logical condition always evaluate to false. For example `where 1=0`. I figured \"is not null\" would work the same way.","56":"Good to know your a \"costs\" kynda guy...","57":"this is my ttab","58":"```select jsonb_object_agg(key, jsonb_build_object('value', value)) from jsonb_each('{\"one\": \"two\", \"three\": \"four\"}')```","59":"Doesn't seem to have such option built-in. You could just get all tables that you want and execute using `--table` argument, you can provide this arg multiple times, e.g. pg_repack -t table1 -t table2 -t ...","60":"ok, I have reviewed supported replication modes and yes this replication is supported: https:\/\/www.enterprisedb.com\/docs\/en\/6.2\/repguide\/EDB_Postgres_Replication_Server_Users_Guide.1.65.html#","61":"I assume u don't see that oid in \"select oid, nspname from pg_namespace\"?.\n\nCheck the following for that oid in their past\n1. pg_type\n2. pg_class.relnamespace\n3.pg_operator.oprnamespace\n4. pg_conversion.connamespace\n5. pg_opclass.opcnamespace\n6.pg_aggregate.aggnamespace\n7. pg_proc.procnamespace\n\nLook through the system catalog to find objects that claim to be in that namespace and provide input like what they are and their history??","62":"no. i started today using python and flask","63":"I love it, TB in docker containers without any backup or upgrade plans done beforehand.\nEven pg_upgrade would result in a longer downtime. Not to speak about to recreate indexes.\nIf you know how to do it, logical replication should be a path with near zero downtime.","64":"Right :)","65":"and that will have a great overhead","66":"Some like python errros...","67":"Seems like\nEmpno::text ~ TotalEmpNo\nor\nposition(Empno::text in TotalEmpNo)>0","68":"Yes it works, provided it's the same version","69":"Dec  4 13:27:41 centos1 etcd: recognized and used environment variable ETCD_ADVERTISE_CLIENT_URLS=http:\/\/192.168.1.220:2379\nDec  4 13:27:41 centos1 etcd: recognized and used environment variable ETCD_INITIAL_ADVERTISE_PEER_URLS=http:\/\/192.168.1.220:2380\nDec  4 13:27:41 centos1 etcd: recognized and used environment variable ETCD_INITIAL_CLUSTER=centos1=http:\/\/192.168.1.220:2380,centos2=http:\/\/192.168.1.221:2380,centos3=http:\/\/192.168.1.222:2380\nDec  4 13:27:41 centos1 etcd: recognized and used environment variable ETCD_INITIAL_CLUSTER_STATE=new\nDec  4 13:27:41 centos1 etcd: recognized and used environment variable ETCD_INITIAL_CLUSTER_TOKEN=etcd-cluster\nDec  4 13:27:41 centos1 etcd: recognized and used environment variable ETCD_LISTEN_PEER_URLS=http:\/\/192.168.1.220:2380\nDec  4 13:27:41 centos1 etcd: recognized environment variable ETCD_NAME, but unused: shadowed by corresponding flag\nDec  4 13:27:41 centos1 etcd: recognized environment variable ETCD_DATA_DIR, but unused: shadowed by corresponding flag\nDec  4 13:27:41 centos1 etcd: recognized environment variable ETCD_LISTEN_CLIENT_URLS, but unused: shadowed by corresponding flag\nDec  4 13:27:41 centos1 etcd: etcd Version: 3.3.11\nDec  4 13:27:41 centos1 etcd: Git SHA: 2cf9e51\nDec  4 13:27:41 centos1 etcd: Go Version: go1.10.3\nDec  4 13:27:41 centos1 etcd: Go OS\/Arch: linux\/amd64\nDec  4 13:27:41 centos1 etcd: setting maximum number of CPUs to 1, total number of available CPUs is 1\nDec  4 13:27:41 centos1 etcd: the server is already initialized as member before, starting as etcd member...\nDec  4 13:27:41 centos1 etcd: listen tcp 192.168.1.220:2380: bind: cannot assign requested address\nDec  4 13:27:41 centos1 systemd: etcd.service: main process exited, code=exited, status=1\/FAILURE\nDec  4 13:27:41 centos1 systemd: Failed to start Etcd Server.\nDec  4 13:27:41 centos1 systemd: Unit etcd.service entered failed state.\nDec  4 13:27:41 centos1 systemd: etcd.service failed.\nDec  4 13:27:41 centos1 systemd: etcd.service holdoff time over, scheduling restart.\nDec  4 13:27:41 centos1 systemd: Stopped Etcd Server.\nDec  4 13:27:41 centos1 systemd: Starting Etcd Server...","70":"There is a very good online tutorial at https:\/\/www.postgresqltutorial.com\/","71":"In telugu","72":"Let's check free disk space","73":"Hello,\n\nFacing some issue with delete sql-\nDelete from table where (date(create_time)) = '2018-09-05';\nRunning infinite time.\n\nSelect is giving result in 5 ms and total 12947 rows\n\nPlease suggest if anything needs to change in SQL?","74":"There's also client-side \\copy in psql...\nFor third-party tools, see pgloader.","75":"I am fromm hyd","76":"Hi friends.. is it possible to setup on demand replication. If yes, kindly share your advice.","77":"what can we do to monitor this","78":"Please share your views","79":"what is the best replication method or architecture?","80":"I was in Amsterdam, Utrech and Den Haag. Very nice towns. I wish I had time to visit Rotterdam as well","81":"Are you trying to set-up topics ? Those are only for groups, not channels afaik.","82":"Can you explain?","83":"Lucian Freud review \u2013 the Queen, Leigh Bowery and the artist\u2019s ex-wives stand brutally revealed\nhttps:\/\/www.theguardian.com\/artanddesign\/2022\/sep\/28\/lucian-freud-new-perspectives-review-national-gallery-london?CMP=Share_AndroidApp_Other","84":"Hello all backup complete in line command","85":"Still, you **should** assume by default that you've **irrevocably** corrupted the database cluster, and it **must **be re-created.\nTell me... did you read the [pg_resetwal](https:\/\/www.postgresql.org\/docs\/current\/app-pgresetwal.html) documentation (where all the above is explicitly stated!) before running it? ;)","86":"Hey guys, I need to learn plsql from beginner to advanced","87":"It will show size of each DB\n\nBut there are also WAL files, temp files, log files","88":"Seems like all the data is not dumping","89":"Let's start with the name. There is no postgre, it's either, postgres or PostgreSQL.\n\nPostgreSQL-XL is multi primary technology. There hasn't been any commit for about four years. Though, do you use other software, that isn't in active development for years?","90":"After installation I was able to connect...after few days I was getting an error \nNo changes on the server or configuration...\nPem status active but Unable to open pem web login.\nTried searching for documents, forums, videos..unable to find the information.","91":"My first professional job, I wrote my own Block Based DB for DOS (last I checked, code was still being used 30yrs later, LOL).  This was just before dBase showed up as popular.\n\nMy second professional Job, on a PDP\/11, we implemented (again), our own 512B block records, and had to create our own index files, then sort them.  We processed TAPES in EBCDIC and did a MERGE after translating to ASCII, to Hard Drives.\n\nThe original system did this in 3 passes of the \"Master File\".  I rewrote it to do it in a single pass.  People were shocked when it was almost so much faster.\n\nThat's when I learned... Simple designs were always best.  We dropped the code base by at least 50% and got faster.\nWe had fewer bugs, and because I created a \"new\" master file (and no longer did updates on the old file).  If we had a TAPE error, or system crash...  No restore was required.  Only when the process completed did we rename all the files and delete the old ones.  (That was learning space vs. time  tradeoffs)\n\nEventually I had to leave and go to college...\nWhere I learned what an RDMS was... LOL...","92":"try (I forgot which one i used):\n`https:\/\/pgchameleon.org\/\nhttps:\/\/pgloader.readthedocs.io\/en\/latest\/ref\/mysql.html`","93":"actually \u0131 can see on qg\u0131s","94":"@Nikolay: Thanks for your help. You gave me a better understanding of what I'm confused about.","95":"I will check that","96":"Okk","97":"Can anyone help me with an issue..","98":"I just did a:\n\nsudo apt upgrade","99":"Really easy. :) Copy pages by bitmap with offsets for each page in file.","100":"Does anyone have an idea for these two aspects?","101":"oh. well, i just compute a new value based on the old `checkpoint_segments`","102":"kiran yasa:\nHi team\n\nAny one from hyderabad postgresql\n\nAdmin","103":"Is this feasible?","104":"For export I created own fork (postgres fork file) _ptrack like _vm and _fsm.","105":"i dont know thats why i am asking how i can seperate the English apps and non english apps","106":"You can drill down to the folder with the highest size in the base directory and can check for a temp file","107":"Hello! I need to optimize query but I don't have any experience with that - can someone suggest what tools to use, what guides to read and so on ? Any information would be appreciated","108":"I guarantee u ... u would like that.... try once...","109":"How to generate unique and sequence values for this","110":"https:\/\/www.postgresqltutorial.com\/postgresql-date-functions\/postgresql-to_date\/\n\nhttps:\/\/www.postgresqltutorial.com\/postgresql-tutorial\/postgresql-interval\/","111":"i receive log in postgres fdw server","112":"But if i upgrade it I will lose bdr functionality","113":"Team one question","114":"Can anyone provide the solution for above error while create the backup","115":"It's in their documentation and if you need consulting, you should pay for that.","116":"@Yaroslav_Schekin Quick Question, I scanned the docs...\n\nis there something special about procedure CURSOR names? (Do they become global during the session while they are open?)\n\nI have proc1() open a cur_this CURSOR ...;\nAnd inside that loop, it calls proc2()\nWhich has it's own cur_this CURSOR ...; \u2014 different query  (And this is a simplified example).\n\nAnd I get an error:\n[2022-10-27 12:52:09] [42P03] ERROR: cursor \"cur_this\" already in use\n[2022-10-27 12:52:09] Where: PL\/pgSQL function test.proc2() line 5 at FOR over cursor\n[2022-10-27 12:52:09] SQL statement \"CALL test.proc2()\"\n[2022-10-27 12:52:09] PL\/pgSQL function test.proc1() line 7 at CALL\n\n\u2014 For the REAL production code I just had to rename the CURSORS that were deeper in the call stack...\n\u2014 It's not an issue AFTER the loop, or after the CURSOR is closed.\n\nvia this code:\n\n```CREATE OR REPLACE procedure test.proc1() LANGUAGE plpgsql AS $$\nDECLARE\n    cur_this CURSOR IS select now() as dt;\nBEGIN\n   FOR r in cur_this LOOP\n       RAISE NOTICE 'proc1: %', r.dt;\n       CALL test.proc2();\n       RAISE NOTICE 'proc1: is back';\n   END LOOP;\nEND;\n$$;\n\nCREATE OR REPLACE procedure test.proc2() LANGUAGE plpgsql AS $$\nDECLARE\n    cur_this CURSOR IS select now() - INTERVAL'1 Day' as dt;\nBEGIN\n   FOR r in cur_this LOOP\n      RAISE NOTICE 'proc2: %', r.dt;\n   END LOOP;\nEND;\n$$;\nCALL``` test.proc1();","117":"But a hacker would need to sit down an figure out a string that executes but not make the query invalid","118":"RE match operators: https:\/\/www.postgresql.org\/docs\/current\/functions-matching.html#FUNCTIONS-POSIX-TABLE","119":"Thanks a lot \ud83d\udc4d","120":"try doing the dump with -T public.sales_order   (excludes it)\nand then try dumping JUST that table:\n-t public.sales_order","121":"(from the horrible screenshot you have posted above, no, Python 3.10 is not supported on Windows. Unsurprisingly, if you look on the bug tracker, you will find a relevant issue: https:\/\/github.com\/psycopg\/psycopg2\/issues\/1371)","122":"Hello does anyone know how I open the Kconfig files in my kernel source code to edit?","123":"You said, all columns in that table are text.\nThough, what exactly are you planning to do?","124":"Learning MySQL in 90 mintues https:\/\/www.youtube.com\/watch?v=LGg_mFgNsW0","125":"quantity of products in stock","126":"in fact, you could have two replicas to test xfs and zfs","127":"Thank you!","128":"Not without a package for scheduling. \n\nBut linux has cron.\nAnd even windows has a scheduler.\n\nI would write\/test a stored procedure. \n\nThen schedule a \nPsql -c \"call proc;\"\n\nShould be easy to test.\n\nYou could also find all tables LIKE ... from information schema, to assist.","129":"I have a jsonb column.  \nlike {'questions':[{'request':'response'},{'request','response'}]}\nHow can I append more objects to the questions array with an update?\nWithout have to select all the objects again and recreate the array?","130":"It's maybe a good idea to describe spam report steps in group info.","131":"One of the most interesting things is the usage of PL\/SQL etc. in the source database and the extent and complexity of that.","132":"How to slove this issue","133":"Also postgresql v14 and upper has a parameter (enable_memoize) does query caching by using hash tables implicitly.","134":"Hi Stefanie , thank you for the quick reply . i tried to find soltiuon but still no results for me.","135":"Hi friends.. how to setup the email config for db alerts","136":"A database is separate from each other database.\nYou can't directly access any object outside of your database.\nYou'll be able to access data in other databases with the PostgreSQL foreign data wrapper.\n\nIf you recently have used MySQL: There it's possible to do cross database access, but it's implemented alike schemas in PostgreSQL.","137":"them you see the pid of process","138":"Which came first, the tsquery or the tsvector?","139":">  It only matters to learn how the system responds\n\nWell, you should have removed this bit before sharing, then, IMHO. ;)\nAlso, using this particular dirty hack is always dangerous, as you're relying on internal query planner behavior which could change in a next **minor** version (due to a bug fix), and your queries might \"break\" (start returning incorrect results).\n\n> (This is a converted system).\n\nYeah, I suspected that.\n\n> But neither of these things are pertinent to the problem at hand.\n\nBut the general approach is.\n\n> I accept that it is what it is.  I am TRYING TO LEARN how to \"encourage\" PG to work around a potentially slow result. \n\nNo, wait. You have your expectations calibrated wrongly, I suspect.\nPostgreSQL is written **by** good programmers (RDBMS developers) **for** good programmers (database developers), therefore if someone uses bad [schema] designs, non-idiomatic queries (perhaps, generated by \"bad\" ORMs), \"workarounds\" and does other Bad Things \u2014 they are doomed to suffer. This is not a joke, and if you expected it to be otherwise \u2014 leave for another RDBMS until it's too late.\nSee https:\/\/wiki.postgresql.org\/wiki\/OptimizerHintsDiscussion , for instance.\n\nI.e. the approach of \"workarounds\" or [dirty] hacks is **strategically** wrong in PostgreSQL \u2014 it won't get you far, here (as the developers actively oppose it). ;)","140":"So, if you max out your CPU with ~300 TPS, I don't think (read) scaling your system will help.\n\nProper tuning probably will, and fixing indexes & bad SQL...","141":"I have configured bart \nAnd on same server my database is running with enterprisedb user \nAnd bart (bart user) is not able to access those archives becoz owner is enterprisedb","142":"what's popular in japan? skype?","143":"But see here","144":"The second paragraph of the documentation of pg_dump clearly states, that you have to use pg_dumpall.\nhttps:\/\/www.postgresql.org\/docs\/current\/app-pgdump.html\n\nIsn't it funny, that PostgreSQL has such a great documentation which is usually describing all aspects?","145":"Hello...all","146":"`SELECT col1, col2 FROM unspent_outputs WHERE (col1, col2) = ANY($1::composite[])`","147":"btw, i succes to fix this im using:\npostgres=# begin;\nBEGIN\npostgres=# set transaction read write;\nSET\npostgres=# create database data_dev;\nCREATE DATABASE\npostgres=# \\l\n                                  List of databases\n   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges\n-----------+----------+----------+-------------+-------------+-----------------------\n data_dev  | postgres | UTF8     | en_US.utf-8 | en_US.utf-8 |\n postgres  | postgres | UTF8     | en_US.utf-8 | en_US.utf-8 |\n template0 | postgres | UTF8     | en_US.utf-8 | en_US.utf-8 | =c\/postgres          +\n           |          |          |             |             | postgres=CTc\/postgres\n template1 | postgres | UTF8     | en_US.utf-8 | en_US.utf-8 | postgres=CTc\/postgres+\n           |          |          |             |             | =c\/postgres\n(4 rows)\n\n\nbut this is just temporary solution","148":"It's not the type that is your problem, but the name...","149":"Hi, \nWhat is main difference between postgresql.conf and postgresql.auto.conf","150":"Thx bro","151":"Pregunta en el grupo de PostgreSQL es en espa\u00f1ol este es en ingl\u00e9s","152":"I need primary key for all the tables , but for some table consider document which has primary key doc_id not available in combined_aud , so while reverting since I need primary key I am getting issue, so need some solution where for such cases what I can do","153":"I don't know anything about postgresql and database","154":"Smth what it is","155":"and DW means DataWare house","156":"I think you're in the wrong group, this is postgresql","157":"Yes I was referred same site , I am not getting backup","158":"on our last PGBR, someone told about a job offer for working with postgreen.","159":"\/start@ProtectronBot","160":"It was discussed in further the other chat, here: https:\/\/t.me\/pg_sql\/18385\nJust FYI.","161":"the easiest way that i know of is using  or a 1) managed service or 2) a kuberentes operator","162":"Check the current instance?","163":"Thanks for the feedback!","164":"Hi Everyone","165":"https:\/\/www.postgresql.org\/download\/\n\nshould have all what you need :)","166":"It's stuck same wal files not getting archived","167":"Combined **how exactly** (I believe I already asked that question)?","168":"perhaps transaction is not commited?","169":"Any scripts or ideas?","170":"you should check with the orm that you're using. I think if it was pure SQL we could help","171":"Can i get some guidance on performing major version upgrade on master slave setup with streaming replication .. with reduced downtime..","172":"Hi everyone, \nHow to set an email alert in EDB PEM tool\nHelp me","173":"Both of them","174":"Nope. And I did not hear about it.","175":"I know of two tools that can achieve that (that = live replication from Oracle to PostgreSQL):\n\n1. Golden gate, it works and is probably the best approach for most cases. But it is quite expensive.\n\n2. SymmetricDS, works with trigger-based replication, so performance is not great and setup is a bit complex. But it does work, and it is free (IIRC, double check that please)","176":"ask about your doubts then","177":"Hi guys , need help\ntrying to run pgbench i got errors. listing will be below.\n[root@pg1 ~]# pgbench -h 10.231.240.25 -p 6543 -U postgres -C -c 1000 -j 10 -T 30 testdb\nstarting vacuum...end.\nconnection to database \"testdb\" failed:\ncould not connect to server: Cannot assign requested address\n       Is the server running on host \"10.231.240.25\" and accepting\n       TCP\/IP connections on port 6543?\nclient 790 aborted while establishing connection\nconnection to database \"testdb\" failed:\ncould not connect to server: Cannot assign requested address\n       Is the server running on host \"10.231.240.25\" and accepting\n       TCP\/IP connections on port 6543?\nclient 669 aborted while establishing connection\nconnection to database \"testdb\" failed:\ncould not connect to server: Cannot assign requested address\n       Is the server running on host \"10.231.240.25\" and accepting\n       TCP\/IP connections on port 6543?\nclient 275 aborted while establishing connection\nconnection to database \"testdb\" failed:\ncould not connect to server: Cannot assign requested address\n       Is the server running on host \"10.231.240.25\" and accepting\n       TCP\/IP connections on port 6543?\nclient 119 aborted while establishing connection\nconnection to database \"testdb\" failed:\ncould not connect to server: Cannot assign requested address\n       Is the server running on host \"10.231.240.25\" and accepting\n       TCP\/IP connections on port 6543?\nclient 99 aborted while establishing connection\nconnection to database \"testdb\" failed:\ncould not connect to server: Cannot assign requested address\n       Is the server running on host \"10.231.240.25\" and accepting\n       TCP\/IP connections on port 6543?\nclient 482 aborted while establishing connection\nconnection to database \"testdb\" failed:\ncould not connect to server: Cannot assign requested address\n       Is the server running on host \"10.231.240.25\" and accepting\n       TCP\/IP connections on port 6543?\nclient 799 aborted while establishing connection\ntransaction type: <builtin: TPC-B (sort of)>\nscaling factor: 50\nquery mode: simple\nnumber of clients: 1000\nnumber of threads: 10\nduration: 30 s\nnumber of transactions actually processed: 27234\nlatency average = 808.471 ms\ntps = 1236.903178 (including connections establishing)\ntps = 1243.726303 (excluding connections establishing)\n[root@pg1 ~]# pgbench -h 10.231.240.25 -p 6543 -U postgres  -c 1000 -j 10 -T 30 testdb\nconnection to database \"testdb\" failed:\ncould not connect to server: Cannot assign requested address\n       Is the server running on host \"10.231.240.25\" and accepting\n       TCP\/IP connections on port 6543?\n[root@pg1 ~]#\n\n6543 - this is pgbouncer's port. pg is on the same host\nneed help i have no idea","178":"Please ?","179":"+1 for ora2pg","180":"Imagine you have a simple table like these:","181":"Done","182":"Thank you so much guys\ud83d\ude0a","183":"\\o\/","184":"disable user postgres, change port 5432, right?","185":"haproxy 8008 checks so patroni yi","186":"sure","187":"This error is In server","188":"Hello. Someone has experience with connection between kepserverex and postgresql? \nTo data logging.","189":"I am facing this error , but do not know how to find the root cause , any one have any idea about this ?","190":"Did I, really? ;)\nMy point was that **any** design simple enough to explain to a \"dumbass of a serial killer\" **won't** meet needs of a modern RDBMS.","191":"Thank you @SneakyPie","192":"\/start@ProtectronBot","193":"I didn't look closely to the Django database config\nthe host was missing, I was connecting to localhost, not to the other host\n\nas I said. dumb thing, sorry","194":"Deleted and kicked, in both groups.","195":"You have to install the extension beforehand.\n\nBut I'd try the aggregation function approach first.","196":"And how to identify whether the upgrade happened with actually using \u2014link option.","197":"I have checked the query plan, But i cannot find anything strange in it","198":"sorry, on aws rds you dnt have access to pg_hba.conf, but here is about access - https:\/\/docs.aws.amazon.com\/AmazonRDS\/latest\/UserGuide\/Appendix.PostgreSQL.CommonDBATasks.html#Appendix.PostgreSQL.CommonDBATasks.Access , may be this help","199":"CREATE TABLE IF NOT EXISTS students (\n     std_id SERIAL PRIMARY KEY,\n     std_name VARCHAR(255) NOT NULL UNIQUE,\n     email_id VARCHAR(255),\n     mobile_no VARCHAR(255),\n     studying VARCHAR(255),\n     branch VARCHAR(255),\n     subjects TEXT [],\n     college VARCHAR(255),\n     country VARCHAR(255)\n     )","200":"You can use PAM modules for auth. https:\/\/www.postgresql.org\/docs\/current\/auth-pam.html And the modules itself can impose constraints for password lifetime, strength, etc","201":"it is good to know, added to bookmarks : )","202":"hello","203":"hi all, after changing the primary key from integer to bigint this simple query on the id won't finish:\n`select id from mytable order by id desc limit 10;\n\n`I've used the instructions from https:\/\/stackoverflow.com\/questions\/33504982\/postgresql-concurrently-change-column-type-from-int-to-bigint","204":"Great, you can likely use the same datawarehouse structure that you saw in SSIS, if you have it working there.\n\nAfter that, you need to simply write your ETL code.\nThe approach I prefer to use is:\nExtract from whatever source you have into an easily loadable format (like CSV,TSV, or the internal \\COPY)\nThen I typically load that into a temporary table.\nWhere I might \"transform\/cleanse\" the data more.\nCreate a streamlined table to do a simple:\n INSERT INTO warehouse.table SELECT * FROM ETL_SOURCE;\n\nIf I am doing updates, or other more complicated stuff.  I usually research and find the most efficient way to do that.\n(You may end up using partitions, and attaching the partition after it is loaded up).\n\nBut that part is up to you.","205":"timestamp without time zone","206":"Free Training via EDB.\n\nhttps:\/\/t.me\/postgresql_lib\/30","207":"Thanks will check","208":"Hi, friends","209":"https:\/\/www.postgresql.org\/docs\/","210":"Thanks for your help!!!","211":"Hi all,  I have 1master, 2 standbys and 2 pgpool using ELB (Elastic Load Balancer) on RDS. does anyone know how I can simulate a failure to test the system availability? I'm new to using pgpool.","212":"A `well-thought-out database of each user's metrics. Could someone indicate a full course or a video about it?`","213":"Hello guys, how can I execute pg_receivexlog command? I can't find this command on usr\/bin","214":"why don't you add target sql server database ?","215":"What tools for migrates MySQL to PostgreSQL?","216":"Hello Guys!\nI'm using partition (time range) and Gin index for  varchar column.\nBut when i search 'string' in that column is too slow.\nPlease give me some advice!!!","217":"```show client_min_messages;\n client_min_messages\n---------------------\n fatal```","218":"I want to need daily full and increment backup use pgbackrest but backup server have not enough storage","219":"Postgres it is big legacy... really big pan of spaghetti C code.","220":"Fixed...problem client application having some problem...","221":"https:\/\/www.flickr.com\/photos\/137027325@N02\/23129790826\/","222":"Yeah ok...!!!!","223":"\u041f\u0440\u0438\u0432e\u0442\u0438\u043a","224":"Hi \nI need help!\nBasically based on two varibles I need to select * from table.\n\nVariable1 and variable2 either one can be passed or both.\n\nSo when variable 1 is passed I need select * from table where column1 = variable1\n\nAnd when variable 2 is passed\nI need select * from table where column2 = variable2\n\nBut when both passed\nI need select * from table\nWhere\nColumn1 = variabl1\nAnd \nColumn2 = variable2\n\n\nHow can I achieve this in one query?","225":"For administration","226":"Hi guys, I have the following question about TDE, I read in a blog that this feature was added for PostgreSQL 14 I downloaded the beta and alpha rpms to test but the option does not come in the initdb binary ? \n\nAre there any other steps or will this feature be added in a future version?","227":"Idle","228":"Please tell me is it possible?","229":"What do you mean!\nRed hat is free, support is paid!\nCentOS is an alternative","230":"Please remove our file.","231":"Although i exported that with UTF8 , i got that bugs","232":"(google cloud)","233":"PostgreSQL Person of the Week interview with: Dimitri Fontaine\n\n#PostgreSQL #PostgresFriends\n\nhttps:\/\/postgresql.life\/post\/dimitri_fontaine\/","234":"Microsoft SQL suppoted this, but postgres is not.","235":"How did you observe this?","236":"Thanks @SneakyPie . I will definitely try that","237":"Any logic I recommend you doing in the appl side. You iterate over the ids and increment them in the appl, after that you can persist the result in you DB","238":"hello guys, is safe to install pg(v15) in network disk attached to my ubuntu server? I thinking about this in the cases where I need to reinstall ubuntu and can restore entire pg databases and configs.\n\nActually im storing data in network storage over tablespace, but this cant be restored if vm was lost (because pg data still in vm)","239":"Hi, there,\non pg 11\nwhy \n```select '2020-02-02'::timestamptz;\n```runs successfully, but \n```create table boarding_pass_may\n  partition of boarding_pass_part\n  for values\n  from ('2020-05-01'::timestamptz) to ('2020-06-01'::timestamptz);\n```gives an error:\n`syntax error at or near \"::\"\nLINE 4:  from ('2020-05-01'::timestamptz) to ('2020-06-01'::timestam...`","240":"Without scheduling thats highly difficult","241":"--pubport 9051","242":"You could simple use unnacent extension and lower (or upper). Or even use full text search capabilitily (with unaccent as part of your dictionary)","243":"See: https:\/\/www.postgresql.org\/docs\/current\/static\/server-shutdown.html","244":"U can ping personally also","245":"Have you tried something, or do you want other people to do your tests\n(Which might bring you on a blacklist at some companies)?","246":"Unless your .dump is compressed and person who did it didn't add .gz or .bz2 or .zip","247":"You right about UI\/GUI.","248":"All","249":"You can start with this one https:\/\/habr.com\/en\/company\/postgrespro\/blog\/441962\/","250":"Hello, can anyone please help with postgres permissions problem?","251":"there is a open issue about that, perhaps can you complement it?\nhttps:\/\/github.com\/sebastianwebber\/pgconfig\/issues\/1","252":"All in our hands.","253":"Thank you, I will","254":"\"Snce the Oracle client shared library is probably not in the standard library path, you have to make sure that the PostgreSQL server will be able to find it. How this is done varies from operating system to operating system; on Linux you can set LD_LIBRARY_PATH or use \/etc\/ld.so.conf.\n\nMake sure that all necessary Oracle environment variables are set in the environment of the PostgreSQL server process (ORACLE_HOME if you don't use Instant Client, TNS_ADMIN if you have configuration files, etc.)\"","255":"okk.. so let me frst try \\i command","256":"Hi all Pg_probackup it\u2019s for incremental backup and recover any one setup share the reference","257":"And?","258":"Can you explain please how to use that .sql ? Im saving it in db then saving another sql I want to analyze and use it as function or how ?","259":"Hi all, can any one advise how to proceed import bulk CSV files to single table. Any third party tool. CSV files are in some other cloud server","260":"fuzzy text search","261":"Why do you want to use `ident` authentication? I recommend avoiding it, unless you know it well","262":"the default was sysv","263":"Ok\ud83d\udc4d","264":"I couldn't send anything, too busy over here...","265":"Hi still facing the same issue \nKindly help","266":"Can we select query to get all users connected to the database last one month in postgresql","267":"Please provide something better than a crappy photo of your notebook.","268":"Nope","269":"Any one have postgre dba videos in telugu","270":"Only single built-in \"engine\", for now, then.","271":"What if you try to copy that cluster, and remove all but the last 2 months data?\nOtherwise, there are tools like https:\/\/github.com\/18F\/rdbms-subsetter (you could check out \"see also\" in its README, too).","272":"Which worked","273":"Can you see this user session at pg_stat_activity view for slave server?","274":"You can start here https:\/\/www.postgresql.org\/docs\/11\/different-replication-solutions.html","275":"Have you checked your binaries are where they are supposed to be?\nDid you use the packages from postgresql.org, or the ones that are from RH?","276":"Absolutely.  Since they work differently under the hood.\nOne examples was CLOB data.  We query and include CLOBs in Oracle.  In PG, we changed the query to get the CLOB data, ONLY as needed.  (Because, effectively, this hos how Oracle does it.  A CLOB is just an identifier to the dat you want, so if you get 10,000 rows with a 500MB CLOB attached to each row.  Oracle only returns a LINK to the CLOB data.  PG was returning the entire TEXT field... Let's just say...  It was a Touch Slower...)\nThe hardest part is SIMPLY that you don't know what you don't know when you are starting.\n\nAnother one we got caught by:\nSELECT ... where field like VARIABLE_NAME  '%';\nWas converted to:\nSELECT ... where field like CONCAT_WS('', VARIABLE_NAME, '%');\n\nbecause Oracle ABUSES  and allows NULLS  to NOT nullify the result...  So CONCAT\/CONCAT_WS() has to be used.\n\nBut PG optimizer UNDERSTANDS the first example, and uses the index because the start of the string is good.\nIn the second example, it punts and does a full table scan (it sees:  \"Function call\")\n\nI could write a book... LOL","277":"I'm not familiar with python but those look like programming issues, not postgresql","278":"many thanks, i need to return ID from partitioned table when new data insert ,is it possible?","279":"","280":"is the default configuration of pg safe?","281":"\ud83d\udc4d","282":"Good idea. I will do that.","283":"and what is the name of the column?","284":"Don't count me in the old ones! I married an 'old guy' to be the youngest forever!","285":"Anything else on the logs that could give a hint?","286":"If there are some at all, they would probably be old.\nAlways use the project page, to install PostgreSQL: https:\/\/www.postgresql.org\/download\/","287":"Please check db name is not case sensitive while creation.","288":"Than use an up-to-date version with a proper implementation.","289":"For example, for some reason in  9.3 the planner chose Index Scan correctly but in 9.5 the planner chose Bitmap Heap Scan... leading to a worse plan","290":"Is there risk for sql injection?","291":"You should be able to destroy them and recreate them","292":"","293":"-- Database Size\nSELECT\n    pg_database.datname,\n    pg_size_pretty(pg_database_size(pg_database.datname)) AS size\n    FROM pg_database;\n\n-- Schema size and percent\nSELECT schema_name, \n    pg_size_pretty(sum(table_size)::bigint) as \"disk space\",\n    (sum(table_size) \/ pg_database_size(current_database())) * 100\n        as \"percent\"\nFROM (\n     SELECT pg_catalog.pg_namespace.nspname as schema_name,\n         pg_relation_size(pg_catalog.pg_class.oid) as table_size\n     FROM   pg_catalog.pg_class\n         JOIN pg_catalog.pg_namespace \n             ON relnamespace = pg_catalog.pg_namespace.oid\n) t\nGROUP BY schema_name\nORDER BY schema_name;","294":"Ah, I see you got some answers in another chat... will move the discussion there, then. ;)","295":"One more article overviewing various count approaches https:\/\/www.citusdata.com\/blog\/2016\/10\/12\/count-performance\/","296":"Hi all\nAny one had version 10.11 installation docs","297":"Yes","298":"--\n-rw-r----- 1 postgres postgres 1.0G Apr 28 14:09 .\/16385\/24626.62\n-rw-r----- 1 postgres postgres 1.0G Apr 28 14:09 .\/16385\/24626.63\n-rw-r----- 1 postgres postgres 1.0G Apr 28 14:09 .\/16385\/24626.64\n-rw-r----- 1 postgres postgres 1.0G Apr 28 14:09 .\/16385\/24626.65\n-rw-r----- 1 postgres postgres 1.0G Apr 28 14:10 .\/16385\/24626.66\n-rw-r----- 1 postgres postgres 746M Apr 28 14:10 .\/16385\/24626.67\n\n\n Is there a way to update the OID for a table, to 24626 ?","299":"For preparation","300":"That's what I meant with production system, it's generalized.","301":":-)","302":"Hello Team,  cam anyone please share a disaster recovery for postgresql - documentation & reference Architecture - for physical stand by .","303":"Hi experts, I have strange issue, in log size.. Even after setting log_min_duration_statement settings to 10 minutes (60000ms) followed by both reload\/restart..still we see queries with less timing appearing in the log file.. Please advise","304":"Ohhh\nI\u2019m sorry for this","305":"Aren't we (community) have good articles on this topic, a minor upgrade made right? I'm going to ask in my Twitter.","306":"Hi\nI have backup schedule to move wal files to cloud storage.. this scheduler runs every 30mins in a day.  But i see more than 48 files per day. Is there any setting parameter to set size of each file?","307":"hello guys \u0131 have two routes on my openlayers which \u0131 publish with geoserver . how can \u0131 publish offline ?","308":"See pg_attributes table or information_schema","309":"we have a small but active community","310":"Hi all, \ud83c\udf34\ud83d\ude0e\ni have 2 tables user and profile\nprofile has relation to user by one-to-one key\ni need automatic insert to profile after insert to user table\ni know about trigres but i not total understend , can please show me simple example for insert tigrer\nthanks","311":"PGConf Brazil 2018: Last Day on Call For Papers!","312":"in postgres, cluster is a running instance of a data directory","313":"Yeah, Actually we thought of the maintainance purpose only, Thinking it might cause burden on server","314":"I have setup a postgresql cluster (with one master node and two slave\/standby node) using Patroni. I want to use HA proxy in front of my cluster for application to connect, in that case do i need to add the database servers (master and slaves servers) to F5 load balancer for  connection routing or HA proxy does the connection routing?in other words HA proxy and F5 load balancer are same ? What will be the benefit of using F5 load balancer and HA proxy?","315":"Yes pg_dump","316":"yes","317":"pgmail or pg_sendmail or another?","318":"9.5 to 9.6 isn't a minor update, it's a major version update.\nWith PostgreSQL 10 the project started the change to name major versions with increasing the previous leading number by one.","319":"So if checkpoints are frequent (with 5GB, they are -- maybe a couple of times per minute), when buffer is touched by your DELETE, a full page is written to WAL many times for the same page.","320":"it is announced afte from clause","321":"you are trying to connect via the socket, and NOT via TCP\/IP.\nlook into pg_hba.conf\n\nAnd review your psql command line parameters\n\nOr your hostname could simply be wrong...","322":"(this message is really old \ud83d\ude31)","323":"Have you look rep manager?","324":"","325":"One thing I will love to see it's postgres using pull requests from github.","326":"First of all thank you for letting me in. I would like to ask a really basic question regarding Postgres and Docker. Can I do it here?","327":"It's possible to tune autovacuum for a table, to have it running more often but then it is finishing faster.\nFor the rest, it's also how big is a row, how many rows fit into a page, is the table overindexed, do you use fillfactor on table and index...","328":"__Opensource tool! Like Postgres itself.__\n\nLol \ud83d\ude02","329":"Hi any can share pgpool installation and configuration to my mail id satishlvvs@live.com","330":"oh, sorry \ud83d\ude05","331":"Yea.. thanks for that.","332":"Some ppl just don't learn \ud83d\ude44","333":"Check this","334":"Hii can anyone help me in postgres?","335":"Thanks","336":"In most cases relational databases do not handle batch processing of large amounts of data very well, not the least of which is RDBMS logging requirements, which set a maximum limit on data changes in one transaction.\n\nMoving lots of data in is an\u00a0operationalconcern, so an operational approach is a good and logical choice.\n\nBreak your file up,externally to the DB (using command line tools), into many smaller files of say 10K each and load them as you would the single large file - keep the chunking logic\u00a0outside\u00a0the DB","337":"Could somebody make me codereview?","338":"In most cases window functions shows better performance than subqueries","339":"I do have it accesible over the default port ( I know this is a vulnerability) which I will change, but I want to remove the malware first","340":"It needs to stop and start PostgreSQL. Since this is a major upgrade surely you scheduled a downtime, right?","341":"CentOS 7.2, Postgresql 9.5","342":"good look  to understand russian @fabio_telles hahahaa","343":"\u043e\u043d\u0430 \u0443\u0436\u0435 \u0435\u0441\u0442\u044c \u0438\u043b\u0438 \u0435\u0449\u0451 \u043d\u0435\u0442?","344":"network access to pgbouncer (ip and port)  and server postgres (ip port 5433)","345":"i am looking for a command to insert data from docs01 in invert01","346":"pg_dump: [archiver (db)] query was: LOCK TABLE public.notificationdefinition_model IN ACCESS SHARE MODE anyone have idea about this .. Backup is failing with this error","347":"And it doesn't take more resources, though it doesn't matter.","348":"Anyone have client installation","349":"It will though, cause the connection to stay in \"idle in transaction\" for a long time, with all locks held and all problems it brings. But that is *precisely* what the OP want to simulate","350":"Can you please give some docs or reference , so I can follow it, Also the allow detach and attach partition","351":"\ud83d\ude02","352":"Good morning all, I try to setup my postgresql 13 and  padmin 4 latest version, however I finished it, when start working\n\n relational (table_name..) not existing\n\nIt pops up every time, is there any solution to solve this issue?","353":"Restore from backup. Or start another cluster using the restored backup directory, and copy the data from there.","354":"Crossposting doesn't help, it's been discussed on the other PostgreSQL group.","355":"I think mine is something like this in PostgreSQL documentation, but when trying it gets error:\n\n\nERROR:  function crosstab(unknown, unknown) does not exist\nLINE 1: select * from crosstab(\n                      ^\nHINT:  No function matches the given name and argument types. You might need to add explicit type casts.\nSQL state: 42883\nCharacter: 15","356":"Do you guys have a guide for configuring barman? I cant find a good guide online.","357":"I have upgraded PostgreSQL database from 11x to 14.6 and started 14 cluster \n\nData is updated in new cluster and Now there is some application issue so want to revert to old cluster. I did not use any \u2014 link option during upgrade \n\nSo can I revert to old one? Will the Data updated post upgrade available if I start my old cluster","358":"I understand your point","359":"https:\/\/www.postgresqltutorial.com\/postgresql-identity-column\/","360":"Yeah that is also in my list.","361":"https:\/\/www.enterprisedb.com\/docs\/kubernetes\/cloud_native_postgresql\/","362":"No, its not returning any error","363":"I had a project to migrade from PG 8.2 on Windows to PG 10 on Linux... my first idea is to use Slony for these.","364":"How to write query in postgresql","365":"If possible send me the course index ?","366":"Can anyone help","367":"PostgreSQL Person of the Week interview with: Keith Fiske\n\n#PostgreSQL #PostgresFriends\n\nhttps:\/\/postgresql.life\/post\/keith_fiske\/","368":"PostgreSQL Person of the Week interview with: Hironobu Suzuki\n\nhttps:\/\/postgresql.life\/post\/hironobu_suzuki\/","369":"","370":"Getting this error while odbc connection","371":"Hi team I have enabled the pg_trgm extension \nThough I am getting the above error in postgres rds instance","372":"when press enter i am getting psql: invalid option -- '\/'","373":"Dear Guys\nI want execute bellow query\nbut faced ERROR\ncan you help me, How to run it?","374":"Show both plans, then. Preferably, on https:\/\/explain.depesz.com\/\nBTW, I meant EXPLAIN (ANALYZE, BUFFERS).","375":"You can use FK in one table too.\n(Maybe it has no sense in this case... But you can;.)","376":"I don't care about SQL injections","377":"when you said \"make sure you can PSQL into the database\" do you mean that it is mandatory for the user with the same name to exist in the OS?","378":"Ok, I can ask to hackers.","379":"Tables*","380":"Hey there.\nSomeone who knows this sintax?\n\n```CREATE CAST (VARCHAR AS MYCUSTOMTYPE) WITH FUNCTION toMyCustomType(varchar) as IMPLICIT; \n\n```?\n\nMy function \n```toMyCustomType\n``` is not work as I expected","381":"Because my disk only save data for 2 years.","382":"Hi if I put the below lines in a shell script and execute I getting an error in the 3rd line. But the same command if I execute in terminal I am not getting any error. Any Idea ?\n\n==========================================================================\n\nrundate=$(date +%Y%j)\n\nexport start_julin=${rundate: -3}\n\nFROM_DATE=date -d \"date +%Y-01-01 +$(( ${start_julin} - 1 ))days\" +%Y-%m-%d\n\n==========================================================================\n\n \n\n \n\nsimple.sh: command substitution: line 3: unexpected EOF while looking for matching \"'\n\nsimple.sh: command substitution: line 4: syntax error: unexpected end of file\n\nsimple.sh: command substitution: line 3: unexpected EOF while looking for matching \"'\n\nsimple.sh: command substitution: line 4: syntax error: unexpected end of file\n\nsimple.sh: line 3: +%Y: command not found\n\n \n\nI know its because of quotes can someone let me know how the quotes should be in order for the script to work ?","383":"It requires third-parties software as bart, pgbackrest, barman,...","384":"Hey","385":"how to copy data from a table to another in different databases","386":"Please note that query execute by system and ran it successfully, but execute manually faced bellow error","387":"hi? want to ask why indexing using btree(created_at) always not working? \n\nI have read in Stackoverflow but still don't understand.","388":"May I ask a question related to mapping an EER diagram?","389":"\ud83d\udc4d thank you","390":"Good morning \nI have a question if I have a table with numbers  1,2,4,6\nAnd I want to find a missing number like 3,5,7,8 how can I do that","391":"I tend to look at source code for this questions : https:\/\/github.com\/postgres\/postgres\/blob\/master\/src\/backend\/optimizer\/plan\/planner.c#L1412","392":"Hi @Laura03021991, I just replied to you in the Spanish speaking channel... apparently there was a problem with the captcha... Laura... al parecer no pudiste entrar al canal espa\u00f1ol porque pusiste la respuesta del captcha en el lugar equivocado... int\u00e9ntalo de nuevo.","393":"It only concerns me.","394":"Hi","395":"Thank you @nik_postgres_ai . Is there a blog or documentation you can point to me ?","396":"I will share a visual to understand the architecture","397":"Hi partition is good for pgadmin9.6 version?","398":"Guys, good morning!\nPlease, can you help me please. I need to create a Functions that erases all the contents of the 'LOG' and 'AUT' columns of all tables that have columns with those names. Would it be possible to create these types of functions?\nI looked for something related to that and I didn't find it.","399":"but I still receive debug log","400":"Actually it saves, but I can't get to save it with Objectionjs","401":"still trying different things","402":"\ud83d\ude02\ud83d\ude02. Once someone told me \"postergeist\" \ud83d\ude02\ud83d\ude02\ud83d\ude02","403":"Okay let me explain","404":"I saw several posts..but seems like its used only for replication and in recovery.conf file..","405":"Once exported I want to import it on the another postgres","406":"How?","407":"You mean a view with dynamic WHERE clauses?\nWhy?\nYou can simply write a query in your application and pass the parameter.\nOr create a view with the statement and query that view by passing a parameter.","408":"dfij94ga9chaod=# select hashrow('accounts', 'act_login', 'myoung');\nERROR:  function hashrow(unknown, unknown, unknown) does not exist\nLINE 1: select hashrow('accounts', 'act_login', 'myoung')\n               ^\nHINT:  No function matches the given name and argument types. You might need to add explicit type casts.","409":"> Case in point \u2014 all the modern ones are **very** complex beasts. ;)\n\"Query optimization is not rocket science. When you flunk out of query optimization, we make you go build rockets.\" \u00a9\n\nThat's a great quote... Is it yours or Tom Lane's or whose? \n\nAnd it's true.  It is probably the single most complex part of the DB.  And the limitations of design decisions on what you can and cannot optimize.  Heck, I believe the FSM was added to help the optimizer.  Statistics help the optimizer.  And some things \"sound great\" but don't always deliver the desired results (JIT Compilation)...\n\nCurious what your thoughts are on OrioleDB?  It seems like they are trying to solve some hard stuff.\nI am hoping we get the needed changes in core, so it works as just an extension... Thoughts?\n\nWhat's the one thing you would like PG to do better?","410":"Not a silver bullet, though","411":"could someone help me please with a very simple thing?","412":"Keeps the table in the cache","413":"Hi all, how to list all the users and it\u2019s privileges inside each database in 1 script","414":"I passed  in Cmd ( psql nameDB < nameMyDb.psql )  to run DB Postgres","415":"appears to be more faster now.","416":"I guess you could try SELECT the adjanced row**s** (there could be two at most... right?).\nAnd then act based on that. You could even try to do it in a single SQL statement (using CTEs), but it feels complicated (not that I actually tried).","417":"Team has anyone migrated from oracle db to postgres","418":"No. It because without quotes PostgreSQL use low-case names\nhttps:\/\/sqlize.online\/sql\/psql11\/b5a853c72125cf3c8b6b0b0dd204d07f\/","419":"Which institute is giving postgresql best?","420":"I have a googleplaystore.csv file which has English and non english word \/ charcters in rows. How do we select only English apps rows","421":"1. install pgadmin\/psql client on your laptop.\n2.open the 2way fire walls to the range of the rds instance(you can get this from the subnet on the rds Configuration tab\n3. Psql client will directly ask for the endpoint\/dbname\/port\/Postgres user&password\nIf you are using pgadmin, you need to register the server with the endpoint\/dbuser &password.","422":"that would be the way here","423":"All sessions were running with same query","424":"Anyone who has encountered such issue? Am on version 12.5","425":"No, not possible. Because\nThe parent table is a template for new partitions.  And parent table is always empty.\n\nSelect * from only parent_table","426":"I just don't see the point","427":"Nani?","428":"That's not been clear to me from your recent message, thanks for letting me know.","429":"Yep","430":"Because it was created with double quotes.","431":"And another thing about NULL:\nNULL is the absence of value!\nTrain your users not to use NULL as an option.","432":"enterprise.com they have excellent courses there and the best part that they're free","433":"Nice. Would be even better if:\na) PostgreSQL's standard (ISO SQL) violations wrt `NULL`s were also in there.\nb) It had realistic examples of appropriate NULL usages in the modeling (table schemas).","434":"Hi ,\npg_wal size too big , it keeped about 20 days wal , what can I do?","435":"Hii Hritik\nCreate Sequence First then Create table","436":"I need some to put me through on it","437":"I filled in the fields in PgAdmin\ud83e\udd23","438":"\\du","439":"PostgreSQL Person of the Week interview with: Valeria Kaplan\n\n#PostgreSQL #PostgresFriends\n\nhttps:\/\/postgresql.life\/post\/valeria_kaplan\/","440":"https:\/\/www.postgresqltutorial.com\/postgresql-cte\/\nThere is a complete SQL tutorial there.","441":"I have a query regarding join","442":"Initialize is not starting","443":"Just came out the other day, didn't it?","444":"I don't understand [DBA](tg:\/\/user?id=1958850040) . The information provided by `\\dnS+` is not enough?","445":"The problem here is \"the server notices\", that is why I suggested taking a look on keep alive settings","446":"I'm looking for help to design a database for animal adoption, I did a lot of research and arrived at the design below, what do you think? Can you help me with ideas?\n\nThe hardest part was dealing with animals\/users\/organizations as a pet can be owned by a common user or an organization.\nCan you help me what can be changed or improved?","447":"On empty table? Will work.","448":"Sure thanks Jessica","449":"rowid generated from concat could be not unique, that's why I would check first to run INSERT :-\/ any solution?","450":"Using cursor loop","451":"Regarding the objects in the repmgr database, which objects are you trying to observe?","452":"They are **not** \u2014 just re-check everything.","453":"my idea its make a wizard to get config","454":"Yep. https:\/\/www.postgresql.org\/docs\/current\/datatype-binary.html","455":"And I am in doubt, how come the binary files are missing, until and unless someone has manually moved\/removed it. Or maybe check your installation type","456":"Hey anyone here who is expert in postgresql database , need some suggestions for a problem","457":"PostgreSQL Person of the Week interview with: Thomas Munro\n\n#PostgreSQL #PostgresFriends\n\nhttps:\/\/postgresql.life\/post\/thomas_munro\/","458":"Is your docker image from an operating system (like debian) or is it a postgresql image?","459":"i make another update on the pgconfig :)","460":"i'm worry, it's installation folders","461":"need help with pa","462":"What's your use case? There's probably a better way to do it.\u2122","463":"depending on whether you use the custom format or not, you will import with either `pg_restore` or with `psql`","464":"Oh. Cool.","465":"","466":"wait i will share","467":"If is not big you can use pg_dump and pg_restore","468":"Stefanie.  Thank YOU!\nHonestly, you have some of the BEST answers.  Direct.  Clear.\n\nI just wanted you to know you are TRULY Appreciated!!!","469":"Anyone in a linux networking group kindly add me or send me an invite link inbox","470":"Hi i have some eroor, what can I do?","471":"psql postgres [optional_database_name]\npsql -U your_user [optional_database_name]","472":"Yes. Physical.  If i am not mistaken Async","473":"I have one more doubt... while taking basebackup it includes the data directory that means it will backup whole data folder right?","474":"Any one have idea about oracle to postgres migration by using ORA2PG?? If u have any documentation plz share.","475":"It is up to you. How could *I* know which cluster(s) are *you* using?","476":"","477":"i have this issue in psql shell","478":"I we send it to personal chart","479":"Is it possible to find the changes that have been made to the  table one month ago in postgres????","480":"There's no practical limit... as well there's no point in artificially increasing those \u2014 the only \"reward\" is reduced performance, in most cases.\n\n> is it possible to dedicate specific workers for specific table \n\nHmm... wait. What \"workers\" do you mean, specifically?","481":"Em... wut?! ;) There's no table like that in PostgreSQL for built-in replication.\nIf you're using something else \u2014 what is it?","482":"1- Learn basic memory and cpu fundamentals (Architecture)\n2- familiarity with C\/C++ will greatly help later in advanced situations.\n3- DAA\n4- move on to learning some database of your choice","483":"Ubuntu is _not_ RHEL.","484":"Just saying, TDE existing at all is only to put a tick on a tick lists. It doesn't bring in any more security.\nAs soon as one has access to a server, it's irrelevant.","485":"Do u have any idea?","486":"second row  column giving same but doesn't check unique validations","487":"Thanks. Our team lead passed logs and confs to dev for analysis","488":"Technically, there's no such thing as \"one database\" in postgres. They are namespaces, derived from template0.","489":"Hello! We have a Linux Postgresql Database cluster working as Active-Passive on Site1. Cluster has been setup using packemaker, corosync and shared storage. Application is connecting to the DB using virtual IP. Site1 is active.\n\nSame set up is there at Site2 but it is inactive. We have to setup the replication process between Site1 and Site2 using virtual ips. Please suggest.\n\nCurrently we have setup the replication from Site1 using virtual ip to Site2 using physical ip of one of the database node(without using the linux DB cluster setup). \n\nOS is Centos7 and Postgresql version.","490":"Hi there! Can you tell me please is there a good tool for scan DB on some warnings about missing indexes on some foreign keys and some related problems like this?","491":"Nice Results.  This COMPLETELY worked!  Easier to code.\n\n` Limit  (cost=0.44..2.46 rows=1 width=34) (actual time=0.007..0.008 rows=1 loops=1)\n   ->  Index Scan using pk_id_dspb on dspb  (cost=0.44..2.46 rows=1 width=34) (actual time=0.006..0.007 rows=1 loops=1)\n         Index Cond: (id = 97658)\n Planning Time: 2.201 ms\n Execution Time: 0.024 ms\n(5 rows)`","492":"I want to calculate a percentage , and group it by the \"expected_check_in\" field.","493":"Oh","494":"Oh yah... Thanks you Sir!!!!","495":"oracle or PG, comes down to the same pattern","496":"PostgreSQL 12 released! https:\/\/www.postgresql.org\/about\/news\/1976\/","497":"Centre for Railway Information Systems","498":"It's easier to help you, if you extract the smallest set of code, w\/o dependencies, that shows us the problem.\nFor example, using  instead of concat() means if ANY argument to  is NULL, you will get a NULL result.  Concat() deals with this.\n\nNext in psql, for example the result will look different based on it's settings.\nNext you add the string to an array.  Then maybe you parse the array?  That could be involved.\n\nFinally, not to pick on your coding style, but unindented code SUCKS to read.\nBut if you produce a simpler example that demonstrates your \"output\" issue.\nWe will have an easier time helping you.","499":"No. You'll need to re-create all of those (better dump \/ script them). :(","500":"@admin","501":"Thanks","502":"Hi everyone","503":"When a role owns a table, which has a trigger that inserts into another table, I get a `permission denied` for that other table.","504":"I use repmgr for replication","505":"Do a print of that string and you'll see what I'm talking about","506":"Wait, but why did you replace the call with `ufn_get_ip_number()` one?\nThe point was just to determine if the function call is the problem, nothing else \u2014 that's why I suggested to remove it and compare.\nSo, to be 100% sure, you still could try it (not that I expect a surprise, here \u2014 the `ufn_get_ip_country_code` call is the problem). ;)\n\nThen, this:\n\n> I did vacuum analyze day_log;\n\nIs the reason for this:\n\n> It also chooses a different plan.\n\nWhich means stats were stale.\n\nAnyway, next step would be to optimize\/rewrite `ufn_get_ip_country_code` (and, perhaps, the function(s) called by it).\nAlso... the fact CTE wasn't inlined means something's preventing it \u2014 perhaps, you declared `ufn_get_ip_number()` `volatile`?\nIf so, **at least** one of the functions has incorrect volatility category.","507":"It is not PostgreSQL causing that timeout, it is something else. Some application drivers do timeout this way, we have an application at work with JDBC and Hibernate that does exactly that","508":"Hi Nice to meet you all","509":"","510":"Fdw still not found clear example","511":"I know it's many to many. But one is a subclass of another entity. I wonder what should I take as the foreign key.","512":"As far as I can see you never show what is in \"wl.sql\". And maybe reduce the wall of text, and only include the necessary details. Like relevant parts of stat activity, not \"select *\".","513":"Verify error logs once. U may find these there but I don't recall any way to find these automatically","514":"barman, pg_rman, pg_arman and my pg_arman its foregin tools.","515":"It is proposal and realisation.","516":"BTC priv.key number is preferred \ud83d\ude48","517":"is your username postgres too?","518":"change your bash_profile like tihs \n[ -f \/etc\/profile ] && source \/etc\/profile\nLD_LIBRARY_PATH=\/usr\/pgsql-10\/lib\nexport LD_LIBRARY_PATH\nPATH=$PATH:\/usr\/pgsql-10\/bin\nexport PATH\n\nPGDATA=\/data\/apps\/test\/pgdata\/10\/data\nexport PGDATA\n# If you want to customize your settings,\n# Use the file below. This is not overridden\n# by the RPMS.\n[ -f \/var\/lib\/pgsql\/.pgsql_profile ] && source \/var\/lib\/pgsql\/.pgsql_profil","519":"command please","520":"Is it recommended to stop the postgres DB before integrating additional node for existing server?","521":"He'll Good evening...\nCan any one please share the Database Maintenance plan Document for SQL server database","522":"You have got **corrupted** database! What \"workarounds\" are you talking about?!\nYou need to a) find out what happened (and then, say, replace the disk; or reconfigure the FS\/OS\/RAID, etc.),  b) prevent it from happening again and c) restore from backup.\nRunning the corrupted database is dumb & you're risking to get even more corruption (esp. as you've no idea what caused it). :(","523":"Emm... wut?! ;) \nWhich linux distro and what exactly do you want to find out?","524":"Thanks man..! You saved my ass","525":"@sebastianwebber thank you \ud83d\udc4d","526":"It\u2019s production","527":"PostgreSQL Person of the Week interview with: Georgios Kokolatos\n\nhttps:\/\/postgresql.life\/post\/georgios_kokolatos\/","528":"Okay, then try seeing if you can process that file as though it is a ZIP STREAM.","529":"Can any one suggest or share a custom script for monitoring postgresql database?","530":"hello guys, sorry for disturbing,\ni've practice postgre xl cluster in my vbox,\nbut i got this error when i try to create db, any sugestion?thankyou so much for the advice\ud83d\ude4f","531":"oh well.. the user left","532":"Hi every one","533":"PostgreSQL Person of the Week interview with: Jaime Casanova\n\nhttps:\/\/postgresql.life\/post\/jaime_casanova\/","534":"this is postgres chat. please avoid advertising your mssql services","535":"Not for all dbs, for small databases, for","536":"Unescaped double quotes","537":"I will have to open each one and copy the code","538":"Guys, someone ever migrate database from mariadb to postgres , if yes how the best method?","539":"I believe so, because that has access to what we need, and works hand in hand in the comparison.\n\nFWIW, I have 30yrs of Managing Developers (and 20yrs of managing CEOs, LOL), so I apply heuristics to getting what I want...  I will always explain my logic, and I am willing to be wrong...","540":"I forgot to mention that I use materialized views for the data presentation. You can refresh them as a background process with REFRESH mv CONCURRENTLY. MVs need a unique index for this, if the data doesn't have that I add a row number for a unique index.","541":"U can download that tool from enterprisedb.com","542":"ok, with double quotes, it did the trick","543":"Then handover to user","544":"","545":"Se de pgadmin","546":"You missed it by a wiiiide margin!","547":"From the situation above, I am looking for a better solution","548":"I was actually trying these things so I just kept the product_id foreign key so that if i get the ids atleast I will implement properly in product table","549":"Thanks!\n\nThis small patch sent to -hackers, here is the gitpod link to test it in 1 click:\n\nhttps:\/\/gitpod.io\/#patchUrl=https%3A%2F%2Fwww.postgresql.org%2Fmessage-id%2Fattachment%2F143428%2F0001-Add-GUCs-to-preven-some-accidental-massive-DML.patch\/https:\/\/gitlab.com\/NikolayS\/postgres\/tree\/main-gitpod\n\n(2-3 min of waiting while Postgre compiles, then `psql` -- and `show prevent_unqualified_deletes;` should work)","550":"In production server , postgres idle sessions are consuming  too much memory and cpu.","551":"Ah, running unsupported versions are so much \"fun\". ;(\nThat has only inheritance... ah, anyway \u2014 I'd just stop beating the dead horse and **upgrade**.","552":"Hi ,\nI have tried to know why not pg_dump, but didn't get it .\nCan anyone explain what is wrong with pg_dump for primary backup","553":"Hi Friends, I have in-depth knowledge on Oracle SQL PLSQL\nand can I survive as PostgreSql developer in IT field","554":"Please help me","555":"It's still dominated by Oracle, I guess?","556":"Hello \n\ndoes anyone know a good Telegram channel for learning Python topics ?","557":"rollback","558":"Thanks, appreciated!","559":"> I cannot access vbsq from outside the AS () clause.\n\nYep \u2014 I didn't test it, so minor fixes are expected. ;)\n\nNow, this is completely different plan, and the estimations are **very** bad, here.\nNote these:\n```->  Seq Scan on logspc.day_log day_log_1  (cost=0.00..69385.32 rows=1 width=12) (actual time=2.827..126.588 rows=180265 loops=1)\n->  Index Scan using idx_day_log2 on logspc.day_log  (cost=0.42..12041.65 rows=849 width=18) (actual time=0.128..254.761 rows=180265 loops=1)\n```Did you re-create the tables, but didn't `[VACUUM] ANALYZE`, for instance?\nAlso, the number of actual rows is different from the previous plan, too...\n\nAnyway, how does the plan for the same query, but without `logspc.ufn_get_ip_country_code()` call looks?","560":"Hi guys","561":"","562":"Another solution is\n```select format('%s-Q%s',extract(year from i),extract(quarter from i)) \nfrom generate_series('2019\/07\/01',current_date,'3 months'::interval) g(i)```","563":"Are you from the past?","564":"Hi, I wanted to certification tor postgresql DBA.","565":"Hi all, I'm looking for PostgreSQL 13 Associate Certification dump exam. Can someone help me?","566":"or use a logical replication tool","567":"pgpool doesn't do fail overs, that's not what is built for.\nFor the rest, as we don't know, what you are planning, it's a bit hard to give advice.\nI personally prefer a setup with Patroni for high availability.","568":"Yes , it does not related with postgress","569":"No, it doesn't. I guess it would be worthless for a correct query, no?\n\n> In this case, why the optimizer estimates 907 and not 0 (or 1...)?\n\nBecause it has no statistics for the table, and therefore uses default estimates (for instance, `SELECT * FROM t;` will estimate rows=2720).","570":"and can you let me knkw why it increased in a day almost 180.gb whar are the reasons it gkt increased?","571":"Data size is not increased much and vacuum was already done","572":"I believe it could be solved with UUIDs. The disadvantage is, that they take more memory than int4 and int8.","573":"depends, if it's a plain sql, psql if it's binary, yes, pg_restore.","574":"hi guys, i need help. i dont import file. see picture","575":"The types decimal and numeric are equivalent. Both types are part of the SQL standard.","576":"Hi All, If any have Postgres  DBA interview questions please let me know","577":"Hola Lisandro. Este grupo es solamente en ingles. Gracias!","578":"I heard of symmetricDS, for instance. Also, you could create linked server to PostgreSQL from MS SQL, and write something based on that, yourself.","579":"What was the exact error line?","580":"How do you do it? And how the path to file looks like? I suppose you can right-click on it and see something like Properties (I'm not a windows user since ~2000...)","581":"i will fix that soon! :)","582":"What is the error here?","583":"https:\/\/twitter.com\/nickbloodh\/status\/1317138067459919873?s=09","584":"Thanks, it's 14","585":"Where should I do this??","586":"Which one should I follow","587":"Ok, Is there any specific role for dump and restore","588":"Thank you Jessica","589":"Hi All,\n\n I am new to postgreSQL and i have one scenario like -\n\nCustomer have master - Slave setup using streaming replication.\n\nI want to migrate DB to AWS RDS, so if i configure pglogical on master will it impact existing streaming replication?","590":"They to use rest datatype equivalent for clob:\n char, varchar, json, jsonb","591":"","592":"CREATE FUNCTION _is_email_valid(p_email TEXT) RETURNS BOOLEAN AS $$ BEGIN RETURN REGEXP_MATCHES(p_email, '^(?:[a-z0-9!#$%&''*+\/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&''*+\/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])^','g'); END $$ LANGUAGE plpgsql;","593":"is there in Russian ?","594":"Hi Jaime thanks for providing","595":"Anyone know why it disconnect immediately?","596":"Depends on your backup strategy.\nFor point in time backups https:\/\/pgbackrest.org\/ or https:\/\/pgbarman.org\/ are both good solutions.","597":"Hii thank you it worked \ud83d\ude0a","598":"","599":"wait wait","600":"No i want to create mysql to mysql","601":"I need postgre sql support and am in hyderabad","602":"hi, I have a big problem \ud83d\ude01 . I have postgres 11 and I  placed the data in an external disk \"PGDATA: \/ mnt \/ vol2 \/ usr \/ local \/ pgsql \/ data \/\". after updating the system with the commands \"yum check-update\" and \"yum update\" I can no longer connect. Maybe I overwrote the configuration file. Is there someone who can help me? thank you \ud83d\ude4f","603":"Once check below commad in root level\nfind \/ -name psql\n\nMay be 2 binaries available","604":"+you can test checksums during full backup.","605":"So if you just checked the counters, it doesn't mean that you have so much bytes stored on disk right now","606":"You can use clock_timestamp() function in your WHERE clause, for example\n```where clock_timestamp()<'2023-09-08 16:00:00'::timestamptz;```\nThe query will process either all rows if it can or as many rows as possible before 16:00 and then finishes. Just because clock_timestamp() is a real-time function and changes its value even while query is running.","607":"I think you have to disable imperva and contact their support.","608":"HI This is Chetan  \nlooking for change with 12+ years of exp as Core oracle dba \nI can join immediately , if you have any opening or any reference , please  share with me\nthank in advance","609":"Can I send the screenshot?","610":"Pgbackrest --stanza=<stanzaname>  --delta --log-level-console=info --db-include=<database name> restore","611":"Messenger has not platform since last week, it's one of major news here in the valley","612":"Most of the software that I used to migrate sql server to postgres are comercial like migration toolkit from enterprisedb ( https:\/\/www.enterprisedb.com\/docs\/migration_toolkit\/latest\/02_supported_operating_systems_and_database_versions\/ )  or ispirer software ( https:\/\/www.ispirer.com\/products\/sql-server-to-postgresql-migration ). Amazon has also Schema convertion tool (https:\/\/aws.amazon.com\/es\/dms\/schema-conversion-tool\/ ) . if your sql server has full of t-sql's you should have a look to babelfish ( https:\/\/babelfishpg.org\/ ) which is a postgres extension that provide you a compatible pl language that understand t-sql and it could reduce the effort of the migration. There is no magic solutions that will resolve every migration issue and you should understand t-sql and plpgpsql in order to tune or decide how to fix them. Related to moving data I recommend using some CDC software like debezium, attunity ...","613":"Where ever the sessions is showing","614":"CREATE TABLE public.\"employeesID\" \n( \n    \"empId\" bigserial NOT NULL, \n     empname character varying(100), \n     empsidx text, \n    PRIMARY KEY (\"empId\") \n); \n \nALTER TABLE IF EXISTS public.\"employeesID\" \n    OWNER to postgres; \n  \n \nINSERT INTO public.\"employeesID\"( \n \"empId\", empname, empsidx) \n VALUES (1, 'David', '[{\"empid\":\"1\"},{\"empid\":\"3\"}]'); \n  \n INSERT INTO public.\"employeesID\"( \n \"empId\", empname, empsidx) \n VALUES (2, 'PDavid', ''); \n  \n  \n INSERT INTO public.\"employeesID\"( \n \"empId\", empname, empsidx) \n VALUES (3, 'PDavid', '[{\"empid\":\"2\"},{\"empid\":\"4\"},{\"empid\":\"7\"}]'); \n  \n  \n INSERT INTO public.\"employeesID\"( \n \"empId\", empname, empsidx) \n VALUES (4, 'PwDavid', '[{\"empid\":\"1\"},{\"empid\":\"7\"},{\"empid\":\"4\"}]'); \n  \n  \n --I need select query like this how to where query get from empsidx column \n  \n select * from public.\"employeesID\" where empsidx in (1,3) and empid=1 \n select * from public.\"employeesID\" where empsidx in (2,4,7) and empid=3 \n select * from public.\"employeesID\" where empsidx in (1,7,4) and empid=3","615":"Its Urgent please help","616":"I got these two recommended about pgbackrest:\nhttps:\/\/youtu.be\/HaqSCskRSkA\nhttps:\/\/youtu.be\/eyda4r6T3Ek","617":"Can you just send me the pg_hba.conf file","618":"Is there anyone who knows the solution?","619":"Have you initdb on pg_node1?","620":"I don't recall extensive public checklists for PostgreSQL installation \/ setup, actually. ;(\nPerhaps, you could google for one... or share what you've got by now so others can add \/ tell something's wrong.","621":"When you hit Control-Z you \"pauses\" the current running process. Until you resume on background or foreground it still paused. Works like Thread.pause() function.","622":"What do you mean?","623":"Indexing, ofc. And if partitioning improved the query response time, you got quite lucky, BTW.","624":"I am looking for support matrix either published by postgres or openssl for version compatibility...","625":"let's talk about how to reproduce the problem","626":"Are you manually running Vacuum in between your updates?\nDo you see a pattern where the Vacuum is \"FAST\"... and then once in a while \"SLOW\"?\n(if you fail to hit a threshold, the amount of work done is minimal).\n\nI have a SIMILAR use case (tons of inserts\/deletes), so it is different.\nI figured out the bloating stuff, and I found that I can VACUUM ANALYZE ever 2million rows (70 Million Row table).\n\nIf you are using AUTOVACUUM and doing those kinds of updates, then the AV may not finish!\n\nYou should NOT see, IMO, that level of Bloat if vacuum is completing.\n\nAlso, how many rows in the table (Row table size is not that important (in bytes))?","627":"Tq","628":"That is a bug, no?\nI meant \"by design\" failures (which some PostgreSQL major contributors are aware about and not going to fix, BTW).\nCould you think of one? ;)","629":"In ~1h, we meet Jacque and Ivan from Greenplum  \u2013 \"Scaling @PostgreSQL to New Heights\" https:\/\/www.youtube.com\/watch?v=n8ACHKgLlvQ\n\nIf petabyte-scale Postgres sounds interesting, join ask questions \u2013 and as usual, like, subscribe, share \u2764\ufe0f","630":"The best formula for maintenace_work_mem is set it around 75% for the biggest table or index. Of course you should put in this acount other memory values like shared_buffers and work_mem to do not occurs an unexpected out of memory","631":"Postgres podcast: Postgres.fm \u2013\u00a0the very first episode is available: https:\/\/postgres.fm\/episodes\/slow-queries-and-slow-transactions\n\n\u2705 Please subscribe, plenty of options are available including iTunes and Spotify.\n\nAnd share in your social network and groups related to databases and development!\ud83d\ude4f","632":"who can help me with that ?","633":"That one ? https:\/\/wiki.postgresql.org\/wiki\/Postgres_Professional_roadmap","634":"Thanks Janine !!","635":"Hi guys","636":"No solution","637":"this is exactly why. The column should be a timezonetz","638":"https:\/\/www.instagram.com\/p\/BKvov3BhbxE\/?taken-by=theildar","639":"Actual problem is user want to write a manipulated data row wise to a file ..","640":"Could you share pgbouncer configuration and monitoring related documents, please?","641":"I am a DBA","642":"Hi yaroslav,\n\nThanx for your reply.\n\n> size of the text representation of the binary value is 2x.\n\nThanx.. I got this .. \n\nDo we have a book where I can read these concepts you have said.\nAnd also concepts related to how memory is allocated while reading a file and how whole process works ???","643":"This is not acceptable in knowledge sharing group.","644":"hello everyone, I have a question about pgbouncer.  There are logs like \"client disconnect while server was not ready (age=XXs)\" in pgbouncer log file. Is there any one who got this log before?    How to interpret this?   Does it cause any performance issues?","645":"I was in the realization of their own function, ran the regression test.","646":"Try pg_config first, to figure out original configuration options","647":"Don't","648":"You can set maintenance memory to lets say 4GB","649":"And please, think outside of that Oracle box.\nThere are a lot of operations where that thingy has been much slower than PostgreSQL.\nIn addition, please don't use partitions in old PostgreSQL versions.","650":"perhaps you can use a `json_agg` function with `GROUP BY ` by the column `id`","651":"\ud83d\ude02\ud83d\ude02\ud83d\ude02","652":"`select  sum(n_dead_tup) from pg_stat_all_tables;`","653":"It's actually being designed as a STORAGE ENGINE for PG.\nSo you would create the table with  a STORAGE clause...\n\nThe challenge right now is that the \"API\" they need to do EVERYTHING is not yet available in PG.\nSo, they are also modifying the PG base code.\n\nBut the goal is to create an extension\/alternate storage engine that has these benefits for the TABLES you create this way.\n\nI am hopeful.  It has some clear benefits.  And if PG can get the API implemented to that level...\nIt opens even more doors in the future...","654":"select * from information_schema.tables;\nwhy the result only displays the tables of information_schema and pg_catalog, but not include other schemas? anyone help me?","655":"It was recently accepted in Europe, right? From what I heard the paperwork was missing (something the manufacturer has to provide).","656":"Hi Boris,\nI guess I found the problem!?\nI was trying to detach oldest partition (min value partition) and while detaching I saw blocking sessions and detach not completed.\nI created default value partition and then detach is completed quickly","657":"please","658":"thanks","659":"Hmm... perhaps, you didn't post the beginning of the question?","660":"Thanks, Yes I am following same docs for postgres.","661":"Lots of open questions, which tool, same server, same disc, same san, database size?","662":"These are practically worthless (yes, you can get **some** clues from that, but that's all ). ;(\nWhat you need is EXPLAIN (ANALYZE, BUFFERS) (or even EXPLAIN (ANALYZE, BUFFERS, VERBOSE)) \u2014 both actually run the query, so it'll take quite a few time. Also, you could use https:\/\/explain.depesz.com\/ for plan analyzing & sharing.","663":"Hi\nI am new to Pstgress. \nI have doubt about Oracle database vs Postgre Database\nI am planning to learn Database so please suggest me which one Better as per career perceptive and which would in demand for long time","664":"Hello Anzo , this thing needs to look at postgresql.conf, especially when the i\/o happens, what postgres version and what os and version do you use etc.?","665":"1. I did, but it was long ago, and a) I forgot almost entirely about how it was done, so\n2. You'd better always ask the **real** question. ;)","666":"@madtyn If both sides are PostgreSQL and you can establish a network connection between both servers, think about using Foreign Data Wrapper.\nhttps:\/\/www.postgresql.org\/docs\/current\/postgres-fdw.html","667":"I have big progress with pg_arman today.","668":"PostgreSQL Person of the Week interview with: Michael Christofides\n\nhttps:\/\/postgresql.life\/post\/michael_christofides\/","669":"but be aware that manage a kubernetes cluster isn\u2019t easy","670":"Client estimate that 3000 concurrent connection will establish and he asks for load balancing....thus y we need active active replication","671":"Obviously the choice of a driver storage as a graph driver of docker is important. Overlay2 gives a good performance, aufs is only valid in developers laptop or not production one.","672":"https:\/\/www.postgresql.org\/docs\/current\/warm-standby.html","673":"yes, we use it (not heavily loaded though), Zalando (developers of it) use it -- in any cluster running using zalando pg operator for k8s, Spilo is used by default","674":"EnterpriseDB has some free courses.\nThe Library has references to many training resources that are available.\nMore will be posted.\nhttps:\/\/t.me\/postgresql_lib","675":"I wants the cheapest hosting provider to host my database to live","676":"Tools are there but not giving proper output , I preferred to convert same manually","677":"I am looking for an efficient open-source tool for postgres administration apart from pdadmin4","678":"I am new to PostgreSQL. I have installed PostgreSQL on linux for first time","679":"Ok .thanks","680":"WOW! Welcome Peter.","681":"For psql, you need 2 things:\n\n1) path to the file (and feed it to` -f `option)\n2) ensure that you've connected to the proper RDS server (options -h, -p, and the database that can be specified without option)","682":"Thank you for the response. I got a solution.","683":"How we can move database loction from one drive to other drive on same system in postgrase.","684":"Hi, any ideas how can I use regex to get all the information in the following pattern - (Aaaaaa (bbb) - ccccc)? \nI'm using '\\((.+?\\))', but this way I catch only the information till ......aaa) and '- cccc' is not included.","685":"Is there any way to get this done?","686":"https:\/\/blog.jooq.org\/postgresql-14s-enable_memoize-for-improved-performance-of-nested-loop-joins\/","687":"","688":"Thank you for your kind answer.\nBut in my case what should I use instead of :mydate?","689":"That is the example I provided then.\n\nIf it is not enough, then you need to specify better your question. Like, what is the name of the table, the column you want to update, the column and value you want to check.\n\nYou can provide your code that you tried to come with so far (even if not working) so we can help you learning.","690":"it seems that this messages are shown only when  log_min_messages or client_min_messages is in DEBUG5 level. Check again both servers for those parameters","691":"ok that's the tool","692":"Thanks","693":"Yep, \u0424\u0451\u0434\u043e\u0440.","694":"Do you think that experts = shamans? ;)\nYou need to **find out** what's wrong, first, and then fix it. \"Experts\" have no fairy dust.\nSo, analyze \/ compare, first.","695":"Well, first of all, what are you going to do with January, February, March, May, July, August, October and December?","696":"pg_upgrade (may not work for betas, ofc), or dump\/restore, as usual.","697":"Tell your users that the DB will be unavailable for a brief period of time.","698":"I recommend using native streaming replication, if it is fills your needs","699":"WHAT TOOL CAN BE USED TO MERGE TWO SIMILAR SCHEMA DATABSES INTO ONE DATABASE","700":"I am NOT 100% certain, but the ONE cause of this that makes sense could be a SINGLE ROW of data that is too big to fit into memory when it is creating the record.  (We ran into something similar with an Oracle Limitation when we tried writing compatible records when our CLOBS were larger than the limit Oracle Allowed for a given row of data).\n\nThis post speaks to this issue in general.\nhttps:\/\/dba.stackexchange.com\/questions\/251317\/postgresql-pg-dump-out-of-memory","701":"Thanks for the options","702":"You can put it under quotes, like \"offset\" but then You'll have to reference it with quotes forever... Does it have to be offset? can it be offsetvalue?","703":"This case proves an scenario where postgres hangs and mysql proceeds.\n\n* create a database called \"siegedb\" in your postgresql localhost server\n* create a table called \"positions\" by running cases\/concurrent_multiple_updates\/1_setup.sql\n* fill that table with 50,000 rows using: java -jar target\/client-1.0-SNAPSHOT-jar-with-dependencies.jar cases\/concurrent_multiple_updates\/2__insert.sql\n* update 1,000 of those rows to have an specific \"latitude\" running: cases\/concurrent_multiple_updates\/3__initial_update.sql\n* now stress the postgres db with: java -jar target\/client-1.0-SNAPSHOT-jar-with-dependencies.jar cases\/concurrent_multiple_updates\/4__concurrent_update.sql\n* you should see postgres failing with \"detected deadlocks\"\n* if you run this exact case in mysql innodb, it succeeds","704":"# service postgresql start\nStarting PostgreSQL 13 database server: mainError: \/usr\/lib\/postgresql\/13\/bin\/pg_ctl \/usr\/lib\/postgresql\/13\/bin\/pg_ctl start -D \/var\/lib\/postgresql\/13\/main -l \/var\/log\/postgresql\/postgresql-13-main.log -s -o -c config_file=\"\/etc\/postgresql\/13\/main\/postgresql.conf\" exited with status 1: 2021-11-01 09:54:26.001 UTC [6507] FATAL: could not create shared memory segment: Function not implemented 2021-11-01 09:54:26.001 UTC [6507] DETAIL: Failed system call was shmget(key=128094, size=56, 03600). 2021-11-01 09:54:26.002 UTC [6507] LOG: database system is shut down pg_ctl: could not start server Examine the log outp","705":"\u0131 wanna add table on the postgresql with using qg\u0131s","706":"@RodrigoMil","707":"System engineer","708":"PostgreSQL Person of the Week interview with: Katharine Saar\n\nhttps:\/\/postgresql.life\/post\/katharine_saar\/","709":"And the devices are connected to the internet using different networks","710":"It's very well documented, take a look at https:\/\/www.postgresql.org\/docs\/current\/auth-pg-hba-conf.html","711":"Postgres.tv: join us in a few minutes on YouTube or Zoom\n\nGUEST: Dimitri Fontaine\n\nzoom linke: https:\/\/us02web.zoom.us\/j\/82940641021?pwd=ZWNZOE1LVFYvRitZdG04aWFpaW9hZz09","712":"DML from Postgres to Oracle using oracle_fdw is much more simple","713":"We are sure we don't want store files with 50mb size in database, this is the only sure","714":"I installed both psql command line utility and pgadmin on windows jump box.. whenevr i am trying to run command from psql to run restore, it is unable to find dump file placed on windows jump box.","715":"Node_name table already  have this nodename","716":"if you know oracle, you'll pick up pg very quickly.  just read the docs, and you'll be good","717":"Yes, understood :)","718":"I know it's a newbie question, but what is it async?","719":"Hi guys I have a quick question.  My pg wal is full and not moving","720":"I am looking  for postgres db designer freelancer","721":"Another possibility would be that 'postgresql' is a generic name of the service that starts all the different versions that are installed","722":"thanks for the link let me start digging on it","723":"I should do that","724":"We are getting foreign key constrain while deleting it from nodes table","725":"Hi","726":"New wave it very nice.","727":"You can dm me if you have questions.","728":"Any more information about OS, PostgreSQL version, cluster size, replicas, extensions might help to give an answer without complete guesswork.","729":"Most likely, and vacuum also","730":"","731":"so i got some task for managed postgrexl cluster with gtm proxy, so i need to practice the default mode of postgre xl, im using default standard installation:\n1 gtm master\n1 coordinator\n2 datanode","732":"PostgresChat (English speakers)\nPostgreSQL-related talks (preferred language: English)\nhttps:\/\/t.me\/postgreschat","733":"\ud83d\udc4dthanks","734":"I don't know if it's better filestream or get file from file system, I mean, store only the file path in database and access it on hdd","735":"Regarding storage, there is also a thing called alignment padding \nThere are several articles about it, e.g., https:\/\/docs.gitlab.com\/ee\/development\/ordering_table_columns.html\n\nI guess this is an answer for 2","736":"https:\/\/l_avrot.gitlab.io\/slides\/null_20191016.html#\/","737":"396 ??","738":"Another option: `pg_dumpall --roles-only`","739":"First check what type of file is dmp. I guest it's a simple sql file that someone has renamed with dmp extension because they used to done with other databases. How to restore a sql file?, simple, just load it with psql -f file.dmp or \\i file.dmp in a psql session.","740":"Select max(length(column name)) from table_name;","741":"Datagrid sometimes can be ridiculous, i strongly recommend you to use psql","742":"I just read, that Imperva supports PostgreSQL since 2023-03-06.\nSounds like you became their beta tester.","743":"Very nice. Where you source code?","744":"Student-Teacher DatabaseConsider the following Entities and their Relationships for Student-Teacher database.Student (s_no integer, s_name char (20), address char (25), class char (10))Teacher (t_no integer,t_namechar (10), qualification char (10),experience integer)Relationship between Student and Teacher is many to many with descriptive attribute subject and marks_scored.Constraints: Primary Key,s_name,t_name should not be null,marks_scored> 0a) Write a cursor which will accept s_no from the user and display s_name and t_name who taught \u2018RDBMS\u2019 subject.b) Write a cursor to accept the class from user and display the student names,subject and marks of that class.c) Write a stored function using cursor to find the details of maximum experienced teacher.2) Movie - Actor Database:Movie (m_name char (25), release_year integer, budget money)Actor (a_name varchar (20), role char (20), charges money, a_address varchar (20))Producer (producer_id integer, p_name char (30), p_address varchar (20))Each actor has acted in one or more movies. Each producer has produced many movies and each movie can be produced by more than one producers. Each movie has one or more actors acting in it, in different roles.Constraints: Primary Key,role should be \u2018Main\u2019,\u2019Supportive\u2019,\u2019Villan\u2019,\u2019Comedy\u2019 p_name should not be null.budget,charges > 045a) Write a cursor to pass a_name as a parameter to a function and return total number of movies in which given actor is acting.b) Write a stored function using cursor to display role wise the names of actors.c) Write a cursor to display producer name that produces more than 2 movies in which \u2018Amitabh\u2019 is acted.","745":"Error massage during installing postgres","746":"Any one have postgresql dba videos","747":"OpenTalks: today we listen to Oleksii Kliukin (Timescale), \"Running a managed service on  Kubernetes and PostgreSQL\".\n\nJoin live (17:00 UTC \/ 10am PT \/ 1pm ET) or watch recorded: https:\/\/youtu.be\/pS73-rAORAs\n\n(It's in less than 3 hours)","748":"The primary key statement automatically generates an unique index as that's standard behaviour.\nAs the PostgreSQL query optimiser can use more than on index per table per query any index that includes the primary key is a duplicate index.","749":"cool. If it's a one-time operation, this is the simplest thing, I think","750":"Okay, if I do it, is it possible to filter the most important information in the Postgres log and populate a control table instantly without relying on an extensive range of tools (SQL, SS, sed, awk, psql, etc...)?","751":"Anybody know what will be the problem","752":"Can anyone help with installation of EDB Postgres with the help os rpm only","753":"I don't know about Oracle, but there are a variety of options there","754":"\ud83d\udc4b","755":"Is there any documentation or reference videos for query optimization?","756":"all students will promote without any exception","757":"Ok","758":"The next recruiter going to that\n list for posting completely unrelated jobs to this group.","759":"Create table","760":"**Show**, don't tell. ;)\nThe **entire **log messages (this one and **all **the ones you got during PostgreSQL restart attempt), **not** some parts of those you felt like being relevant, that's the point.","761":"They use SeLinux enforced Postgres with multilabel security. Looks alike sepgsql extension but much more integrated with operating system","762":"can some one please give me study material","763":"WOW! Why not in Github?","764":"Thank you","765":"Akhilesh Kedarisetty:\nI am getting incomplete startup packet in both master and slave logs\n\nWhat might be the reason?","766":"Question is if OP was referring to the product or the general approach ;-)","767":"\/start@ProtectronBot","768":"There's a code i see I can run on psql. Let me run it and see the sizes","769":"Actually i think it's good question. When i have PG12 primary and secondary, can i upgrade secondary to PG13, stream to catch up, then failover?","770":"If any one configured , could you share any useful link specifically for PostgreSQL 14 ?","771":"Hello everyone, does anyone help me with postgresdb cold back up at the file system level?\n\nI have copied the complete directory of data files to new data location and restarted db with new data location. But still I'm not able to see the tables","772":"yes, the speed is what you indicated","773":"I have no idea -- It would be better if you ask a concrete question","774":"ChatGPT will help ua lot.. plz try it once","775":"I prefer that over tablefunc extension.","776":"error: no pg_hba.conf entry for host \"**.***.***.***\", user \"test\", database \"testDB\", no encryption","777":"Real usecase we encountered: creating a new secondary on beta environment, found issues in replication, dba wanted to truncate data and instead executed the command on production, unintentional mistake. Looking to prevent this through a lock.","778":"Jsonb +1","779":"how can i create my server ?","780":"Works like a charm with 14:\nformat\n---------\n 2019-Q3\n 2019-Q4\n 2020-Q1\n 2020-Q2\n 2020-Q3\n 2020-Q4\n 2021-Q1\n 2021-Q2\n 2021-Q3\n 2021-Q4\n 2022-Q1\n 2022-Q2\n 2022-Q3\n(13 rows)","781":"Thank you let me try..","782":"I can hash it code-side, but can I join the results on postgres side?","783":"depending on the destination type I think you could do a `string_agg`, `array_agg` or `json_agg` to agregate the data you need","784":"Pg_restore -U Postgres -d restoretest < c:\\users\\RK\\document\\backup","785":"see https:\/\/hub.docker.com\/r\/cybertecpostgresql\/pg_timetable\/tags how alternative","786":"Ok I will check","787":"https:\/\/docs.aws.amazon.com\/AmazonRDS\/latest\/UserGuide\/USER_UpgradeDBInstance.PostgreSQL.html","788":"Hello any mongo dB group??\n\nPlease add me","789":"You can check out EnterpriseDB training.\nI started with many years or Oracle DBA too. It is a perfect place to start as the core-technologies are very similar (relational db theory from Codd and Date).","790":"the BEST way to do this is to USE some tools.  Find a tool you like.\nAnd go see what requests are out there to enhance it.\n\nEven if your changes are not accepted, you will gain the experience of learning how to build the software.\n\nIt will also help if you already use the software.\nThe problem with being 'new' is that you are new to everything.\n\nAlso, work on \"skills\", like playing with gitpod and how you can grab a project and build it there.\nFinally, try ChatGPT for Brainstorming (Don't trust it's technical answers).\nBut you can tell it about yourself.  Your goals, your skills.  And then ask what projects you could start with, or how to find projects.\nAlso ask it what skills are most in demand, etc.  Develop those.\n\nGood Luck!","791":"not likely. post the full stack trace","792":"I have seen that people claimed timescaledb upgrade, even the have lost their data or it was impossible to query data","793":"IMO simplest thing to do is have some table with rows for each of the procedures that need to be controlled in this way, then You explicitly do a 'select for update' for appropriate row within the procedure","794":"I just discovered some stuff from hacker news","795":"i don't no idea","796":"Yes... I like Barman a lot.","797":"how can i find it ?","798":"WITH base_state AS (\n  SELECT\n    ( SELECT COUNT(*) FROM (\nSELECT lastmile_occupancy.baseoccupancy_ptr_id, COUNT(basic_logistics_parcel.id) as c\nFROM lastmile_occupancy\nINNER JOIN basic_logistics_baseoccupancy ON (lastmile_occupancy.baseoccupancy_ptr_id = basic_logistics_baseoccupancy.id)\nLEFT OUTER JOIN basic_logistics_shipment ON (basic_logistics_baseoccupancy.shipment_id = basic_logistics_shipment.id)\nLEFT OUTER JOIN basic_logistics_parcel ON (basic_logistics_shipment.id = basic_logistics_parcel.shipment_id)\nWHERE NOT basic_logistics_baseoccupancy.is_deleted\nGROUP BY lastmile_occupancy.baseoccupancy_ptr_id\n\nHAVING COUNT(basic_logistics_parcel.id) > 1)\nAS subquery ) AS all_multi_parcel_last_mile_occupancies,\n    ( SELECT COUNT(*) FROM (\nSELECT lastmile_occupancy.baseoccupancy_ptr_id\nFROM lastmile_occupancy\nINNER JOIN basic_logistics_baseoccupancy ON (lastmile_occupancy.baseoccupancy_ptr_id = basic_logistics_baseoccupancy.id)\nLEFT JOIN basic_logistics_shipment ON (basic_logistics_baseoccupancy.shipment_id = basic_logistics_shipment.id)\nLEFT JOIN basic_logistics_parcel ON (basic_logistics_shipment.id = basic_logistics_parcel.shipment_id)\nLEFT JOIN basic_logistics_pack ON (basic_logistics_baseoccupancy.id = basic_logistics_pack.occupancy_id)\nLEFT JOIN basic_logistics_parcel_packs ON (basic_logistics_pack.id = basic_logistics_parcel_packs.pack_id)\nWHERE (NOT basic_logistics_baseoccupancy.is_deleted\n        AND ((basic_logistics_baseoccupancy.dropper_id IS NOT NULL\n             AND basic_logistics_baseoccupancy.status = 'notdropped')\n            OR (basic_logistics_parcel_packs.parcel_id IS NULL\n                AND basic_logistics_baseoccupancy.status = 'reserved')))\nGROUP BY lastmile_occupancy.baseoccupancy_ptr_id\nHAVING COUNT(basic_logistics_parcel.id) > 1\n) AS subquery\n\n ) AS multi_parcel_that_rejected_by_courier\n)\nSELECT\n  (cast(multi_parcel_that_rejected_by_courier as float)\/cast(all_multi_parcel_last_mile_occupancies as float) * 100) AS result, all_multi_parcel_last_mile_occupancies,\n  multi_parcel_that_rejected_by_courier\nFROM base_state\n\n\n\nif you see this , you can find out what I want to do , I think.\nIt is just that query , that is not efficent.\nbut I want to write it with the case when statement and a single intermadiate table ( single select and joins)","799":"All,  I am doing oracle to postgres migration using ora2pg...\n\nTable output was created, I found a table creation have Anydata type for a column, it not allowing to me create this table.... What is alternative for ANYDATA for postgres to use... Plz suggest","800":"Always use the download section at https:\/\/www.postgresql.org\/download\/\nNo matter which OS you want to install PostgreSQL.\nThe Windows sections will point to the EDB pages, where you can download PostgreSQL for Windows.\nAnd please do everyone a favour, don't use PostgreSQL on Windows in production. In addition, you won't get all extensions for Windows, if you don't compile them on your own.","801":"I wouldn't narrow this to PostgreSQL ;-)","802":"It doesn\u2019t have to be running","803":"Because those are indentifiers, not literals (values).\nI.e. you'll need format() for that.","804":"while i can do same from pgadmin.","805":"Hello all how can i add that line to my bash script and get executed normally ? (psql -U postgres -c \"CREATE USER user1 WITH ENCRYPTED PASSWORD'admin123' CREATEDB\")","806":"And a Sout Saret? Both people manage FB groups which are a bit neglect.","807":"Wait, how do you mean?\n```SELECT E'{\"a_json_object\": \"with_a_\\x00_byte\"}'::json;\nSELECT E'{\"a_json_object\": \"with_a_\\x00_byte\"}'::text;\n```All give:\n```ERROR:  invalid byte sequence for encoding \"UTF8\": 0x00\n```I.e. `0x00` simply cannot be stored in postgres text-alike types, period (this is what the article is all about).","808":"I'm gay","809":"Use window functions for such tasks","810":"Thanks for the reply. Can you share some website where I could refer this event trigger and try to implement it Live environment","811":"Ah, i understand now, pardon me. It was created using pg_dump -Fc ? \"Custom format\"","812":"Login from the right psql folder","813":"Hi anyone know how to read Current Activity AWS RDS?","814":"guys .. is it good to run postgres in docker ?","815":"Ah... you've misunderstood the sentence (perhaps, English is not your first language?).\nIt means that it writes enough information into the WAL to be able to support running queries (which can be **only** read-only) on the another PostgreSQL server (replica). Is it clearer now?","816":"Hi janine, \n\nYes, I have 521 sequences, how can we give them all\n Is there any specific role for take dump","817":"Check de connection: telnet 192.168.1.175 5432","818":"you can solve it by verifying if Postgres is running or not. If it is running, there are two possibilities:\n- it's not running on port 5432\n- it's placing the sockets in a different directory.","819":"Any commit or rolckback dismiss the lock","820":"Postgresql 9.5 on ibm storwize v 3700","821":"how this happens?","822":"As source code installation","823":"We're starting now -- join us in YouTube, http:\/\/postgres.tv","824":"did you try this one?","825":"Hi everyone \n\nI have been looking for an answer to the following question without success:\n\nWill the processes walsender and walreceiver always running on a streaming replication regardless use of slots or archive mode?\n\nCan anyone help me to understand it, please?","826":"Trigger","827":"https:\/\/github.com\/vranac\/Sublime-psql-build-system\/tree\/master","828":"My apologies if this is hurting you","829":"Hmm... but this is basically the same as the one you rejected here: https:\/\/t.me\/postgreschat\/11368 , no?\n\n> cause it\u2019s not supported by python\u2019s asyncpg\n\nIt's not asyncpg to blame here, but PostgreSQL, BTW.\n\n> ok i had to create a composite type, is this stil efficient?\n\nMost probably not (it's one of the \"other ways, but those are even more complicated\"). ;)\nCheck the query plan if you're interested.","830":"Hello guys \nI need your help to set the retention policy in pgbackrest.\nCustomer 15 days retention with pitr and currently we are taking  weekly full backup and daily different backup \nCan some suggest what retention i have to put in pgbackrest.conf to achieve the required retention","831":"don't worry. you can work on this issues and make it better. see like a new challenge. :)","832":"like this.","833":"That's necessary? Perhaps just postgresql will work fine.","834":"hey colleagues\nCould anyone help me please with Amazon AWS RDS PG10?\nI'm trying to drop user1 (which is not rds_superuser) by user2 (which is). I'm getting an error:  [42501] ERROR: permission denied to drop role. I already tried to  grant all privileges on database for user2, but drop user still fail. What I have missed?\nAlso I have notice that  during the day that cluster switched between Writer|Reader without any reason, and there is no human explanation of the reason in log. I'm not a pro with RDS though it looks very strange for me.","835":"Exactly :)","836":"It does not create a Linux user, it only creates a PostgreSQL role.\nTo access it, just run\npsql -u test postgres\nIt also does not create a database named test, you have to add a database, to which you want to connect to.","837":"+----+\n| Id |\n+----+\n|  1 |\n|  2 |\n|  3 |\n|  4 |\n|  5 |\n|  6 |\n|  7 |\n|  8 |","838":"So only need to migrate the data.. code can be changed manually","839":"I don\u2019t know but you tried to add this parameter in postgresql.conf?","840":"Everyone","841":"Also, I suggest **everyone** who is new to text messaging \/ chats in general to read this: https:\/\/libera.chat\/guidelines\/\nWhile some of the advice there concerns technical limitations of the IRC technology, the social aspect of it is quite sound (and far from \"it's only @Yaroslav_Schekin opinion!\" \u2014 these guidelines are there because conflicts like that happened **over and over**, and because those guidelines tend to **work** for preventing said conflicts).","842":"in PSQL, do \\h GRANT\nand it shows you the syntax.","843":"@sebastianwebber you can try now","844":"I mean sort or this","845":"Hello folks, I want to check my understanding regarding SSL\/TLS connection to postgresql. \n\nOnly when the sslmode is require (with root ca present), verify-ca or verify-full the client will verify the SSL certificate that postgresql server present.\n\non the default mode (prefer), client will try to initiate SSL connection regardless of the certificate being presented by server, including when the certificate is expired. Is my understanding correct? Are there anything I missed? Thank you","846":"Thanks! I will try fix it fast.","847":"Yes we do have streaming replication for the standby slaves in the cluster. But we have also have logical replication requirements for a different purpose where limited set of data goes to, say for some auditing purpose. Anyways great insights taken.","848":"There might be an issue with the version of repmgr you are running, or maybe you are missing repmgr for your target version of Postgresql","849":"Hi everyone, I have one question\n- now I am using gin index for jsonb with jsonb_path_ops\nbut not working index search, of course , I used contain operator @> but not working.\n\nbut it works well if table would have only one column(jsonb column), but if would have other columns, not index, only seq scan. I am working on Postgresql 12.2\n\nI need your help. thanks","850":"That's today, in 40 minutes: https:\/\/twitter.com\/ascherbaum\/status\/1457744180109848583","851":"what the difference between them ? any way it will lead to mark row as deleted and insert new one","852":"debian, I can execute: pg_ctl    restart. but when I run : sudo systemctl restart postgresql. I get error: Job for postgresql.service failed because the control process exited with error code. another server might be running; what can I do ?","853":"With pg_ctl it showing process","854":"I'm doing a test right now.  Really, a schema with almost 1000 tables and using a query to know which table there are two columns with a given name, is not easy.","855":"perhaps i can help. i will put that on my personal todo list","856":"So can anyone help what might be the reason for increase in records count for the same query?","857":"You can use pg_dump schema-only mode to dump table definition. And ```copy``` command with query clause to dump desired dataset only","858":"Hi Friends, Can we restore Postgres database from AWS S3 ?","859":"Take a look at window functions at the tutorial: https:\/\/www.postgresqltutorial.com\/postgresql-window-function\/","860":"you're welcome.","861":"Can some one please help.. for loop is having millions of records to process and it should run only between 3 -4 pm CT . What ever the no of records it can process in that time frame it need to run. Then process should stop. Basically I need for loop should be controlled with time frame.","862":"Pls help for this setup","863":"Create a role and grant the privs to the role and then assign that role to the dB users","864":"Pg now no hash partition, has anyone done hash partition?","865":"At the beginning of the backup, a checkpoint needs to be written on the server the backup is taken from. Especially if the option\u00a0--checkpoint=fast\u00a0is not used, this can take some time during which\u00a0pg_basebackup\u00a0will be appear to be idle.\n\nThe backup will include all files in the data directory and tablespaces, including the configuration files and any additional files placed in the directory by third parties, except certain temporary files managed by PostgreSQL. But only regular files and directories are copied, except that symbolic links used for tablespaces are preserved. Symbolic links pointing to certain directories known to PostgreSQL are copied as empty directories. Other symbolic links and special device files are skipped. See\u00a0Section\u00a052.4\u00a0for the precise details.\n\nTablespaces will in plain format by default be backed up to the same path they have on the server, unless the option\u00a0--tablespace-mapping\u00a0is used. Without this option, running a plain format base backup on the same host as the server will not work if tablespaces are in use, because the backup would have to be written to the same directory locations as the original tablespaces.\n\nWhen tar format mode is used, it is the user's responsibility to unpack each tar file before starting the PostgreSQL server. If there are additional tablespaces, the tar files for them need to be unpacked in the correct locations. In this case the symbolic links for those tablespaces will be created by the server according to the contents of the\u00a0tablespace_mapfile that is included in the\u00a0base.tar\u00a0file.\n\npg_basebackup\u00a0works with servers of the same or an older major version, down to 9.1. However, WAL streaming mode (-X stream) only works with server version 9.3 and later, and tar format mode (--format=tar) of the current version only works with server version 9.5 or later.\n\nExamples\n\nTo create a base backup of the server at\u00a0mydbserver\u00a0and store it in the local directory\/usr\/local\/pgsql\/data:\n\n$ pg_basebackup -h mydbserver -D \/usr\/local\/pgsql\/data\n\nTo create a backup of the local server with one compressed tar file for each tablespace, and store it in the directory\u00a0backup, showing a progress report while running:\n\n$ pg_basebackup -D backup -Ft -z -P\n\nTo create a backup of a single-tablespace local database and compress this with\u00a0bzip2:\n\n$ pg_basebackup -D - -Ft -X fetch | bzip2 > backup.tar.bz2\n\n(This command will fail if there are multiple tablespaces in the database.)\n\nTo create a backup of a local database where the tablespace in\u00a0\/opt\/ts\u00a0is relocated to\u00a0.\/backup\/ts:\n\n$ pg_basebackup -D backup\/data -T \/opt\/ts=$(pwd)\/backup\/ts","866":"What I expect was any conf setting, for example encoding at source and target database which are defined at ora2pg.conf ? also if I were you if you claim for help I could share to this channel, commands executed , output, ... any data. People tend to be busy doing their jobs and there are not going to help if you only say, this thing is not working...","867":"Thanks  \ud83d\ude0a","868":"Which record is being deleted? Just inserted one?\n\nAre there any triggers on table in which insert is happening?","869":"","870":"So even without using the pg_stop_backup(), would it have been gone to consistent recovery state?","871":"Read \"SHOW CONFIG\" here: https:\/\/www.pgbouncer.org\/usage.html","872":"Don't know bro","873":"Wow","874":"Thus, each time will delete 1 week of data","875":"Postgres certificate , do we need ?","876":"How* can i remove the log files in pg_wal","877":"Can anyone tel me how to resolve this error.??","878":"If im doing so postgres throws error - either ```invalid input syntax for type integer:``` coz next value is string, or ```null value in column \"id\" violates not-null constraint ``` if im using DEFAULT","879":"Did you mean how?\nHow should I know, who is administrator of your database?","880":"When using for enterprise data","881":"All I did was install it and start using it","882":"\u0131 had select another role mistakenly","883":"Postgres complain about non empty tablespace when attemting the drop","884":"In Russian about difference http:\/\/postgrespro.ru\/products\/postgrespro9.5","885":"qq, i have seen a simulation of wraparound via a blog of fatdba. Do I talk sense,  if I stop the db just around wraparound, make a filesystem and start the db from the copy (updating relevant configuration in postgresql.conf) be able to replay it as many times from the snapshot? I know I have to try this, incase someone has already does that. Just asking, in that case one can simply upload the snapshot on cloud buckets,  make it available for everyone to get a feel of it without waiting for a simulation to complete over days :)","886":"After connection?","887":"REM   Script: fhgyt\nREM   askjskjsSeverity: ERROR \nTimestamp: 5\/1\/2022 2:09:30 AM \nNode: node02_clddblaspia02 \nThread: MAPPING \nProcess ID: 132647 \nMessage Code: CMN_1022 \nMessage: Database driver error... \nCMN_1022 [DROP TABLE IF EXISTS  wmap_fi.crma_party_alternate_names_t \nFnName: Execute Direct -- [Informatica][ODBC PostgreSQL Wire Protocol driver][PostgreSQL]DEBUG: VDEBUG; relation \"wmap_fi.crma_party_alternate_names_t\" does not exist(File namespace.c; Line 421; Routine RangeVarGetRelidExtended; ) \nFnName: Execute Direct -- [Informatica][ODBC PostgreSQL Wire Protocol driver][PostgreSQL]NOTICE: VNOTICE; table \"crma_party_alternate_names_t\" does not exist, skipping(File tablecmds.c; Line 1057; Routine DropErrorMsgNonExistent; ) \n]","888":"in other words I need one func to transform 10.1234 to 10.12 and another one to transform it to 10.13","889":"``` jsonb_insert('{\"questions\":[{\"request\":\"response\"},{\"request\":\"response\"}]}', '{questions, -1}', '{\"newrequest\":\"newresponse\"}', true)```","890":"https:\/\/stackoverflow.com\/a\/21798517","891":"Yes","892":"google dan so'ra yaramas","893":"Not sure to be honest.","894":"PostgreSQL Person of the Week interview with: Markus Wanner\n\n#PostgreSQL #PostgresFriends\n\nhttps:\/\/postgresql.life\/post\/markus_wanner\/","895":"1. Bring down 1 pgpool. All the load should go through the 2nd  one without causing failover to the standbys. \n2. Failover master rds to standby. Pgpool should redirect all the traffic to the newly promoted primary. This might have downtime while the switch is happening.","896":"Is there any function in postgresql which works same as SUBSTRING_INDEX function in MySQL?","897":"Wrong group?","898":"Hmm... why don't you file a bug report into ora2pg tracker, too (not sure how it works, though \u2014 if it, say, uses text-format `COPY`, they won't be able to fix that)?","899":"?","900":"First, lets work this problem for MY UNDERSTANDING.  \nI will have to do this MORE than just this one time, I am sure of it.\n\nI want to understand how to read\/see what you are seeing.\nI want to understand this \"other way\" I could have approached the problem without materializing the view (because that just simulated splitting the transaction... Which is a trick I've used many times in my career, because it simply gives me more control)\n\nAgreed that it is better not to jump to any conclusions... But at least I EXPLAINED in advance what I did.  In case I had to absolutely run the long query...\n\nAnd THANK YOU!","901":"i'm starting to make a JSON API to compute the data","902":"If you read PostgreSQL docs, you'd already know all of that I wrote you. ;)\n\n> what should be my co figurations so that this works?\n\nYou'd better start with one tailored for your language (English?).\n\nAnd then proceed from there... you see, PostgreSQL's FTS is **not** a pre-configured solution that fits everyone \u2014 you're rather given some pieces, and it's expected **you**'ll construct the solution that fits **you** from those... ;(\nWhile quite flexible (and could be made extremely so by (ab)using low-level mechanisms behind it), it could take long time to get right for a specific \/ non-trivial use case.","903":"You can use sudo:\n\nsudo -iu postgres psql ...","904":"lets talk here on ptBR: https:\/\/t.me\/postgresqlbr","905":"anyone can help?","906":"Good morning, You want create database link from postgresql to mysql?","907":"For very basics, you can just watch some videos from freecodecamp. No need to spend money for a paid course.","908":"Dump & restore, then rename table?","909":"Means","910":"shure","911":"Understood, is there a script which will use patroni api to automate the logical replication when failover happens.","912":"I had no idea this existed.","913":"The problem here is not PostgreSQL. PostgreSQL calls a system function, that seems not to be available in Kali.","914":"Like this?","915":"Hey read about pgbouncer monitoring https:\/\/news.ycombinator.com\/item?id=18069479","916":"Cast it to date and cast it to time.\nselect now()::date, now()::time;","917":"Google is your friend, document of Bart is available on enterprise dB site","918":"Ok. Thanks for the response","919":"because i searched on Internet a lot and I am not sure","920":"Okay","921":"pg_dump -v --host=abc.postgres.database.azure.com  --username=postgres  --column-inserts --data-only --dbname=abcd > data-abcd.sql","922":"Speaking of `NULL`s \u2014 this one https:\/\/modern-sql.com\/concept\/null is also pretty good (and, as I see now, it even describes Oracle's behavior discussed above).","923":"[Nikolay](tg:\/\/user?id=7386851) thanks for info, I will try out 2.1 version this week","924":"You about FB Messanger?","925":"How","926":"If I was to restore to a different instance I would have to rewire the whole connection so I want to avoid that. Is it possible to do a point in time recovery to the same instance or backup on the same instance?","927":". Type \"man pg_upgradecluster\" at the prompt.\n. Read it.\n. Compose the command that fits your situation.\n. Run it.\n...\nProfit! ;)","928":"PostgreSQL Person of the Week interview with: Ashutosh Bapat\n\nhttps:\/\/postgresql.life\/post\/ashutosh_bapat\/","929":"Take in consideration your database size","930":"Hey folks, have any here, so use barman for to make postgres backup?","931":"What did you try to quote?","932":"Hi, I have a master slave setup in our environment. I want to block a particular user from accessing the slave. is it possible to achieve this by making an entry at pg_hba file?","933":"shure.","934":"Correct","935":"What client does you use for work?","936":"honestly i don't know much about it.","937":"I'm trying to use the bartender for postgres 14 backup, but when I check it returns this:","938":"You can create a tablespace.  Which creates a HARDLINK in the data folder to another folder.\nDoing this, we spread our data over multiple drives.  You can then create tables\/indexes with the TABLESPACE ts_xyz option to utilize it.\n\nIf that helps!","939":"Ohh sorry, my bad. i send text immediately","940":"Well, excpet for unlogged tables and unclean shutdown. But that is another beast.","941":"Thanks Mohan,  I want to migrate Data from Oracle to Postgres using ora2pg","942":"???","943":"As that is dependent on a lot of things, your hardware resources, your use cases, data structure, etc., there's no guide that will work for everyone and everywhere.\nIf you don't know what to do, either, start learning or hire a professional DBA.","944":"oh... I ported my cmake build for Postgres 9.6","945":"Like column A should be x and column B should be y, but these xy values are always different","946":"Ask L\u00e6titia","947":"https:\/\/sqlize.online\/sql\/psql14\/359e4ce0807845a352cba37242a30655\/","948":"command ?","949":"How can looping be fixed","950":"Then sorry to say ,it's not possible","951":"but still same issue is persisting","952":"Cool article but not updating regulary as Leo's.\nFor example \"Never add a column with a default value\" is obsolete for Postgres 11. (And it was true fo large tables with heavy load only.)","953":"Hi all can set a time for particular table auto vaccum??","954":"No, actually my application team want to change password policy, and they want popup if they are using same previously used password","955":"What error it gives?..\nIt's correct command...\nCheck column and table name...\nAlso check there column and table exist or not!.\nAnd then check data type of column name...","956":"Yes it is postgres on rds","957":"Do anyone have Datasphere postgres dba videos?","958":"Xxxx-contrib-xxxx","959":"pg_dump is not a backup solution. Restore won't get faster.\nThink about real backups that can also do point in time restores.\nYou might use pg_basebackup, but it's a bit harder to maintain this.\nBut there are other great backup tools, take a look at those: https:\/\/pgbackrest.org\/command.html\nhttps:\/\/pgbarman.org\/","960":"Where do you want to clone it to? Another server?","961":"Yes I got the hint for applying patch","962":"Drop table cascade","963":"Have You tried Apache kakfa plus posgresql?","964":"hello","965":"Function call api","966":"thnx","967":"PostgreSQL Person of the Week interview with: Daniel Westermann\n\nhttps:\/\/postgresql.life\/post\/daniel_westermann\/","968":"i opened","969":"Hi All","970":"The union (not union ALL) perform distinct values internally","971":"That seems to be the wrong direction (and the wrong group).\nIn PostgreSQL has a concept implemented that is called Foreign Data Wrappers.\nWith that, there's nearly no data source, that can't be accessed from within PostgreSQL.\nAFAIK, there nothing implemented in Oracle, that could do these things.","972":"SQL is an Industry Standard, not a product!\n\nDo you mean MySQL, MS SQL, SQL Anywhere, SQLite?","973":"When have huge date in oracle table","974":"PostgreSQL index defragmentation should generally be handled automatically by Autovacuum","975":"[23\/6 22:13] Roberto Sobreira: tenho uma tabela que tem um vencimento a cada m\u00eas , esta em ordem cada linha da tabela ta com sua data de vencimento - valores.. uma abaixo da outra --- preciso transformar em coluna em postgres tipo assim Janeiro, Fevereiro, Mar\u00e7o , ....\n[23\/6 22:14] Roberto Sobreira: estou tentando assim mas n\u00e3o fica um depois do outro\n[23\/6 22:14] Roberto Sobreira: select a.codlocacao, \n(select b.valorreppagto  from imob_reppgto b where b.codlocador = a.codlocador and b.codlocacao = a.codlocacao and \n((EXTRACT(Month from a.dtvencimento))= '01') and ((EXTRACT(year from a.dtvencimento))= '2019')\nand a.cotatotal = b.cotatotal) as rep_janeiro, \n\n(select b.valorreppagto  from imob_reppgto b where b.codlocador = a.codlocador and b.codlocacao = a.codlocacao and \n((EXTRACT(Month from a.dtvencimento))= '02') and ((EXTRACT(year from a.dtvencimento))= '2019')\nand a.cotatotal = b.cotatotal) as rep_fevereiro \n\n\nfrom imob_reppgto a where a.codlocador = 2955 and ((EXTRACT(year from a.dtvencimento))= '2019') \nand ((a.tipomovcotas = 'ENL') or (a.tipomovcotas = 'ALG') or (a.tipomovcotas = 'ADT')) order by a.dtvencimento","976":"I moved data directory of my postgees server by mistake.. For few seconds... Will it impact db?","977":"I am on macbook and installing from terminal","978":"-bash-4.2$  \/usr\/pgsql-14\/bin\/pg_ctl -D \/var\/lib\/pgsql\/14\/data\/ -l logfile start\nwaiting for server to start.... done\nserver started","979":"Depends, you could use logical replication as that would work with different versions.\nAnother approach could be using foreign data wrapper. The PostgreSQL fdw can read and write.","980":"No problem. If you need more extensions, here is an example how you can get them https:\/\/gitlab.com\/postgres-ai\/custom-images (published images: https:\/\/hub.docker.com\/r\/postgresai\/extended-postgres)","981":"And by default, I don't look at screenshots, no matter what.","982":"No idea about your specific situation \/ setup, but usually yes.","983":"so I think the zcat option is the way to go","984":"Might be your DB configuration parameters are not up to the mark. Have to do some performance tunings","985":"Heh, I got totally different ideas looking at db structure:\n\n1. SEX TEXT. Trust me, it easier this way.\n2. Address fields are too small. Try filling in SomeCity, district YewHill, street FinalBorderWithDoomToday, house 29, apartment 246b. Duplicated street names, split apartments, cute local navigation stuff \u2014 adding just 2 address lines instead of try to rationalize that mess will make your life easier in the future.\n3. Cnpf, rg, cpn are not good choices for field names. Imagine me looking at all this two years later and trying to understand what's going on, taking to account I'm not going to spend too much time fixing it as a seasonal worker.\n4. It's better to store password hash and password salt instead of password, for the sake of user security.\n\nSorry, this is mostly random non-SQL rants for later stages of development.","986":"Thanks.","987":"Just open the the cursor you need in an if.\nOr use a query for the cursor to make that cursor using dynamic SQL statements.\n\n\nif person = 'idiot' then\n  query := 'select * from table1 where person = $1';\nelse\n  query := 'select * from table2 where person = $1';\nend if;\n\nopen cur_person for execute query using person;","988":"","989":"DMS is logical","990":"is not as I'm calculating bank interests, I'm just using item prices from stores and shops, maybe adding shipping costs\n\nI'm not messing around with cent fractions, as your link said","991":"Yes my brother.","992":"https:\/\/www.postgresql.org\/docs\/current\/pgupgrade.html#PGUPGRADE-STEP-REPLICAS","993":"i like too much.","994":"Without showing your code, how should we guess, what you are doing to return a value from a function?","995":"Hi, Can someone give some prior information regarding dblink ,how can we use it","996":"New group for RDS queries \u261d\ufe0f","997":"you","998":"Because I saw exclusvelock on this table","999":"Look at DELIMITER option for COPY"}}