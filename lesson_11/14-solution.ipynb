{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e02c65bd",
   "metadata": {
    "id": "e02c65bd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005fec94",
   "metadata": {
    "id": "005fec94"
   },
   "source": [
    "## Задача\n",
    "\n",
    "Предобработать текст следующим способом:\n",
    "\n",
    "- разбить текст на слова\n",
    "- привести все к нижнему регистру\n",
    "- убрать из текста все точки, запятые и скобки\n",
    "\n",
    "Найти в тексте самое частовстречаемое слово."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97738b0-7a18-43bb-b267-6397d2cc4ca8",
   "metadata": {},
   "source": [
    "Способ через цикл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb90133-2984-4197-ae2e-f92f5523dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def preprocess_text(x):\n",
    "    res = []\n",
    "    for word in x.lower().split():\n",
    "        for sign in string.punctuation:\n",
    "            word = word.replace(sign, '')\n",
    "            # print(word)\n",
    "        res.append(word)\n",
    "    return res\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0de14c-d286-4f2b-88c1-2e7194aeff43",
   "metadata": {},
   "source": [
    "Способ через регулярки (на практике лучше использовать что-то такое)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "177ae928-7733-4c04-947f-d290e2328050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(text):\n",
    "    return re.sub(r\"[^\\w\\s]+\", '', text).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52655f8a-8683-4500-a7a2-080e6b15c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4590e63a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4590e63a",
    "outputId": "275f0e8a-2e9c-433a-dfe9-ff01c681476e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'текст': 4,\n",
       "         'разобьем': 1,\n",
       "         'этот': 1,\n",
       "         'на': 1,\n",
       "         'слова': 1,\n",
       "         'приведем': 1,\n",
       "         'к': 1,\n",
       "         'нижнему': 1,\n",
       "         'регистру': 1,\n",
       "         'затем': 1,\n",
       "         'уберем': 1,\n",
       "         'пунктуацию': 1,\n",
       "         'точки': 1,\n",
       "         'запятые': 1,\n",
       "         'и': 1,\n",
       "         'скобки': 1,\n",
       "         'а': 1,\n",
       "         'потом': 1,\n",
       "         'найдем': 1,\n",
       "         'слово': 1,\n",
       "         'которое': 1,\n",
       "         'встречается': 1,\n",
       "         'чаще': 1,\n",
       "         'всего': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Разобьем этот текст на слова, приведем к нижнему регистру. Затем уберем пунктуацию (точки, запятые и скобки). А потом найдем слово, которое встречается чаще всего. текст текст текст.\"\n",
    "\n",
    "# Ваш код здесь\n",
    "Counter(preprocess_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd03cb-c090-4d0d-8005-6714183d0533",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Написать функцию для обработки предложения при помощи стемминга для английского языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5c3245-b72a-429b-8694-d6db5dfae280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89adb968-c524-48b8-ad3e-0f6001054672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence_eng(text):\n",
    "    return ' '.join(map(stemmer.stem, preprocess_text(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1741c8-a700-4f1a-bd82-f99bd9af70f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unit test for the porter stemmer from nltkstemport import creat a new porter stemmer'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"\"\"Unit tests for the Porter stemmer\n",
    ">>> from nltk.stem.porter import *\n",
    "Create a new Porter stemmer.\n",
    "\"\"\"\n",
    "\n",
    "preprocess_sentence_eng(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d59563-be04-45e1-93e2-0a137fe5725b",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Применить стемминг к тексту и добавить колонку `text_stemmed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b083f6ad-9753-453f-b84a-c8f7ffaf5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89bd0c93-99a4-4b1c-b96c-60afd3760384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>Will ? b going to esplanade fr home?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text target\n",
       "0     Go until jurong point, crazy.. Available only ...    ham\n",
       "1                         Ok lar... Joking wif u oni...    ham\n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...   spam\n",
       "3     U dun say so early hor... U c already then say...    ham\n",
       "4     Nah I don't think he goes to usf, he lives aro...    ham\n",
       "...                                                 ...    ...\n",
       "5567  This is the 2nd time we have tried 2 contact u...   spam\n",
       "5568               Will ? b going to esplanade fr home?    ham\n",
       "5569  Pity, * was in mood for that. So...any other s...    ham\n",
       "5570  The guy did some bitching but I acted like i'd...    ham\n",
       "5571                         Rofl. Its true to its name    ham\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/spam.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05178405-e94b-4d93-855d-65ca1487e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_stemmed'] = df['text'].apply(preprocess_sentence_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c24a2413-4b66-48dd-834c-8488d10929c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go until jurong point crazi avail onli in bugi...\n",
       "1                                ok lar joke wif u oni\n",
       "2    free entri in 2 a wkli comp to win fa cup fina...\n",
       "Name: text_stemmed, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_stemmed'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14cb91b-467a-4282-a7ee-b5174ef13835",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Выбрать метрику и модель, векторизовать текст и научиться искать спам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc6dfba-7554-4531-b540-b0b42253aad6",
   "metadata": {},
   "source": [
    "Можно взять любую метрику, которая учитывает дизбаланс классов. Например, `f1_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329a0190-1dc2-4f77-92e6-93063806cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dce89b86-d6a5-487c-b392-a4badcb17d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target_num'] = df['target'].map({'ham': 0, 'spam': 1}) # переводим таргет в числа\n",
    "train, test = train_test_split(df, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03241c2f",
   "metadata": {
    "id": "03241c2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9125683060109289"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = CountVectorizer()\n",
    "x_train = bow.fit_transform(train['text_stemmed'])\n",
    "x_test = bow.transform(test['text_stemmed'])\n",
    "y_train = train['target_num']\n",
    "y_test = test['target_num']\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860f0f2-ab62-42bc-a015-75ea1d556045",
   "metadata": {},
   "source": [
    "Скопировали - вставили - поменяли на TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7bc0326-17e7-404e-a1a8-1337d47cdd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.861271676300578"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = TfidfVectorizer()\n",
    "x_train = bow.fit_transform(train['text_stemmed'])\n",
    "x_test = bow.transform(test['text_stemmed'])\n",
    "y_train = train['target_num']\n",
    "y_test = test['target_num']\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152e01da-f6e7-4d03-9e8b-95d129895d61",
   "metadata": {},
   "source": [
    "Получилось хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34815c1f-59ea-457e-83d6-96628f23725c",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Попробовать случайный лес для классификации документов. Использовать пайплайны для решения.\n",
    "\n",
    "Выборку необходимо как и раньше делить на треин и тест."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171ea4bc-e17b-408c-9343-5d3d8cd142fa",
   "metadata": {},
   "source": [
    "Напишем кусочки пайплайна и запустим перебор пайплайнов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36bc940a-33d9-446a-94f1-895c19fad4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "695c30a2-54d9-450b-8480-89511085324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasePreprocessor(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Класс для базовой обработки текста - нижний регистр и пунктуация\n",
    "    \"\"\"\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        return np.array(list(map(lambda x: ' '.join(preprocess_text(x)), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29b2f7eb-33ce-4745-9cf2-e4e3fccd2a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['test123test _ test test test'], dtype='<U28')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BasePreprocessor().transform(['test123test _ tEst - test @ Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24fdffbf-73bd-4e37-bb72-dc7efb426a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmerEng(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Класс для стемминга на английском языке - разбиваем по словам и применяем к каждому стеммер\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _stem(self, word):\n",
    "        return self.stemmer.stem(word)\n",
    "    \n",
    "    def _transform_text(self, text):\n",
    "        return ' '.join(map(self._stem, text.split())) \n",
    "\n",
    "    def transform(self, x):\n",
    "        return list(map(self._transform_text, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14f3deba-fdfe-42ec-8f39-59d6d860997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alway test test']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StemmerEng().transform(['always test tests'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8922560a-d642-4fc0-b76d-b8ec70a442c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_results = []\n",
    "\n",
    "# На вход подаем необработанный текст\n",
    "x_train = train['text']\n",
    "x_test = test['text']\n",
    "y_train = train['target_num']\n",
    "y_test = test['target_num']\n",
    "\n",
    "# Перебираем модели и векторизацию\n",
    "for vect in [CountVectorizer(), TfidfVectorizer()]:\n",
    "    for model in [LogisticRegression(), RandomForestClassifier()]:\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"base\", BasePreprocessor()), # препроцессинг тоже можно подбирать\n",
    "                (\"stem\", StemmerEng()), # как и стемминг/лемматизацию\n",
    "                (\"vect\", vect),\n",
    "                (\"model\", model),\n",
    "            ]\n",
    "        )\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        y_pred = pipeline.predict(x_test)\n",
    "        metric = f1_score(y_pred, y_test)\n",
    "        fit_results.append(\n",
    "            {\n",
    "                'vect': vect.__class__.__name__,\n",
    "                'model': model.__class__.__name__,\n",
    "                'f1': metric,\n",
    "            }\n",
    "        )\n",
    "\n",
    "fit_results = pd.DataFrame(fit_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09c51686-4cb1-44dc-acd8-04ef092eb26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vect</th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.912568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.874286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.874286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.861272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              vect                   model        f1\n",
       "0  CountVectorizer      LogisticRegression  0.912568\n",
       "1  CountVectorizer  RandomForestClassifier  0.874286\n",
       "3  TfidfVectorizer  RandomForestClassifier  0.874286\n",
       "2  TfidfVectorizer      LogisticRegression  0.861272"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_results.sort_values('f1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ae818",
   "metadata": {
    "id": "2c7ae818"
   },
   "source": [
    "## Задача\n",
    "\n",
    "Используя word2vec классифицировать тексты\n",
    "\n",
    "Алгоритм:\n",
    "\n",
    "- разделить на треин и тест выборки\n",
    "- обучить word2vec на треин выборке\n",
    "- написать функцию для составления вектора по документу (для этого нужно посчитать среднее векторов всех слов)\n",
    "- обучить модель, оценить результаты\n",
    "\n",
    "Для начала лучше взять небольшую выборку, чтобы проще было писать код (например, 2000 в треин и 5 примеров в тест).\n",
    "\n",
    "Когда убедились, что все работает, брать весь датасет.\n",
    "\n",
    "Функции, которые могут помочь и подсказки:\n",
    "\n",
    "- `model.wv.key_to_index` - словарь токен->номер токена. Можно взять список всех слов отсюда.\n",
    "- `model.wv[word]` - получаем вектор по слову. Не забываем применить предобработку!\n",
    "- может случиться так, что word2vec не будет знать какого-то слова из обучающей выборки. Тогда этому слову присваиваем нулевой вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d501a5d",
   "metadata": {
    "id": "2d501a5d"
   },
   "outputs": [],
   "source": [
    "# TBD =)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
